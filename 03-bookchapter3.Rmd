---
title: "When the Pen Becomes a Sword: Retired Military Officers and Opinion Commentary"
author: "Peter M. Erickson"
date: |
  `r format(Sys.time(), '%B %d, %Y')`
abstract: |
  
  _This is the third chapter of the book._  
  
geometry: margin = 1.15in              # margin widths
fontsize: 12pt                         # text size
bibliography: manuscript.bib              # bibliography file
biblio-style: authoryear               # citation style
reference-section-title: References
urlcolor: blue                         # links to external URLs
citecolor: black                       # links to bibliography
linkcolor: magenta                     # internal figures, footnotes, etc.
indent: true                          # paragraph format
                                       # true for indented paragraphs
                                       
header-includes:
    - \usepackage{booktabs}
    - \usepackage{longtable}
    - \usepackage{setspace}
    - \usepackage{sectsty}
    - \usepackage{paralist}
    - \usepackage{fancyhdr}
    - \usepackage{lastpage}
    - \usepackage{indentfirst}
    - \usepackage{array}
    - \usepackage{multirow}
    - \usepackage{wrapfig}
    - \usepackage{float}
    - \usepackage{colortbl}
    - \usepackage{pdflscape}
    - \usepackage{tabu}
    - \usepackage{threeparttable}
    - \usepackage{threeparttablex}
    - \usepackage[normalem]{ulem}
    - \usepackage{makecell}
    - \usepackage{xcolor}
    - \usepackage{caption}
    - \usepackage{rotating, graphicx}
    - \usepackage{dcolumn}
    - \usepackage{ragged2e}
    
output: 
  bookdown::pdf_document2:
    keep_tex: true
    latex_engine: pdflatex
    number_sections: false
    toc: false
    fig_caption: true
    citation_package: biblatex
    includes: 
      in_header: 
        - latex-preamble.tex
  bookdown::htmldocument2: default
  bookdown::word_document2:
      toc: false
---

\doublespacing 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r loading-library, include=FALSE, echo=FALSE}
library("here")       # file paths
library("tidyverse")  # workhorse package
library("tidylog")
library("kableExtra")
library("knitr")
library("ggdag")
library("dagitty")
library("gridExtra")
library("broom")
library("dplyr")
library("reshape2")
library("pacman")
library("ggrepel")
library("writexl")
library("lme4")
library("bucky")
library("scales")
library("stargazer")
library("rstatix")
library("brglm")
library("margins")
library("IRdisplay")
library("texreg")
library("cowplot")
library("mice")
library("miceadds")
library("bookdown")
library("sandwich")
library("mitools")
library("modelsummary")
library("sf")
library("tidycensus")
```
\newpage

# When the Pen Becomes A Sword
\doublespace
In May of 1959, retired General of the Army Omar Bradley gave an address on the occasion of Armed Forces Day in New Canaan, Connecticut. During the address, the retired five-star General, who 15 years earlier played a significant role in the Allied invasion at Normandy and in the subsequent campaigns in Europe to defeat Hitler's forces, stated, "I am convinced that the best service a retired general can perform is to turn in his tongue along with his suit and mothball his opinions" [Omar Bradley in @times_bradley_1959]. Bradley went on to say that "...it is not my purpose to contest the right of anyone -- even a retired officer -- to speak what he chooses. But when he presumes to speak with an authority which derives from his retired rank, he should exercise a sensible degree of circumspection and be discreet in the choice of causes to which he lends his name" [Bradley in @times_bradley_1959]. 

In context, Bradley was responding to his former British colleague and fellow hero of World War Two, retired British Field Marshall Viscount Bernard Montgomery, who had just days before publicly criticized the leadership of US President Dwight Eisenhower --- who also was a retired five star general and previous boss of both Montgomery and Bradley in Europe during the second World War [@times_bradley_1959]. By admonishing Montgomery, Bradley seems to convey the idea that it simply is not wise for a popular retired military figure to weigh in on contemporary political issues. Though he does not explicitly invoke or allude to the existence of any central principles of civil-military relations in his remarks, it is nevertheless clear that Bradley possesses concern about the potential for retired officers --- especially those with high rank --- to influence politics inappropriately by speaking out. 

Sixty-one years later, in the Summer of 2020, a remarkable turn of domestic events in the United States sparked a flurry of retired military officers who spoke out publicly, and in a manner that runs antithetical to the spirit of Bradley's advice. This occurred during a period of turmoil for the United States. In May, a Minneapolis Police officer killed an unarmed black man named George Floyd, whose arrest and the subsequent moments leading up to his death were caught on camera and played by major media outlets for several nights in a row. Protests began to erupt across the nation, which was already on edge after the Coronavirus had, for all intents and purposes, shut the nation down a few months earlier.  

It was in this difficult environment that the military soon found itself at or near the center of the public's attention [@feaver_military_2020]. To begin with, the Secretary of Defense, Mark Esper, and the Chairman of the Joint Chiefs of Staff, General Mark Milley, appeared in controversial photos in the press after they had been summoned to the White House in early June. These photos sparked controversy because they were as President Trump walked to St. John's Church for a photo shoot right after security forces had displaced throngs of protesters Lafayette Square, which neighbors the White House.^[According to Esper, neither he nor Milley knew about the plan to walk to the church, nor about the photo shoot that occurred there.  They were both, according to Esper, under the impression that they would merely walk into Lafayette Square themselves to check on the status of the protests that had been occurring.  See @macias_pentagon_2020 for more.] The images of the Secretary of Defense and the Chairman of the Joint Chiefs of Staff on the White House lawn, at a time when the use of military forces was being raised as a potential option to quell riots, distraught many Americans as the nation writ large was grappling with the broader issue of race in America. Within just a few days, Secretary of Defense Esper then publicly disagreed with the possibility of President Trump invoking the Insurrection Act of 1807, which in fact might have led to the use of active-duty military forces to quell the domestic riots that were occurring [@esper_secretary_2020]. General Milley himself then apologized during a virtual graduation address at the National Defense University, telling those graduating senior military officers that he "should not have been there," and that his actions had "created a perception of the military involved in domestic politics" [@milley_official_2020].

The confluence of these events seemed to turn on a spigot of public opinion commentary by several high-ranking retired military officers, so much so that some civil-military relations scholars concluded that the events of the Summer of 2020 marked "the most intense division between a president and retired officers in a generation" [@brooks_let_2020]. However, there was also discernible variation in the tone and tenor of the remarks these officers made. To be sure, each expressed a deep concern about the prospect of active-duty forces confronting peaceful protesters in the US, thus violating protections held by the First Amendment of the US Constitution [@brooks_dismay_2020; @dempsey_former_2020]. But some officers went much further than others in their criticisms, leveling direct insults at President Trump, including his fitness to lead [@goldberg_james_2020], his administration's broader policies on race in America [@allen_moment_2020], and his overall leadership abilities during a time of crisis [@mullen_i_2020]. 

In the weeks and months that followed, several other retired and even active-duty military officers engaged in similar behavior that certainly pushed against the limits of and in some cases violated one or more of the central principles of civil-military relations. For instance, a group of junior Army officers, all of whom were recent graduates of West Point who finished at or near the top of their respective classes, wrote a lengthy treatise calling for West Point to acknowledge its culture of "whiteness", to adopt a host of "anti-racist" measures, and to explicitly state that "Black Lives Matter" [@askew_anti-racist_2020]. Another example included a pair of retired Army lieutenant colonels, both of whom who were somewhat known within defense circles for helping the military revise the military's counter-insurgency doctrine more than a decade earlier when the military was heavily engaged in Iraq and Afghanistan, who penned an open letter to the Chairman of the Joint Chiefs of Staff to prepare to remove the President from office after the upcoming 2020 Election by force if necessary [@nagl__2020]. Indeed, throughout the Summer of 2020 and well into the fall ahead of the 2020 Presidential Election, much of the public commentary published in major media outlets and authored by military actors seemed to openly challenge the President of the United States and one or more of his policy stances. 

This chapter systematically explores one specific type of political behavior that military actors can undertake. In particular, the chapter explores the behavior of military actors public commentary, and the degree to which such commentary adheres to the central principles of civil-military relations. The answer to this question can certainly help us put in perspective the activities of 2020 outlined above. Was the Summer of 2020 simply an anomaly? Have there been other periods like 2020 before in terms of what retired military officers said publicly? While these are important questions in and of themselves, this chapter will also inform the even more important and broader question explored in this book, which is what factors, if any, drive the degree to which military and civilian actors violate the central principles of civil-military relations? 

Using advanced statistical methods to explore public commentary written by military actors over a period of _four decades_, this chapter argues that rising political polarization is in fact moderately associated with an increase in the frequency with which military actors violate the central principles of civil-military relations through the opinion pieces they publish. This chapter will show that as the level of polarization rises in America, so too does the frequency with which military actors publish opinion pieces in major media outlets that violate the principles of civil-military relations also rise. The evidence explored in this chapter is consistent with the notion that at the root of heightened polarization in a domestic society, there exists contestation over issues in the political square that directly involve _the Image of God_ and its application in politics --- a claim that in the previous chapter, I argued explains why rising polarization provides a _motive_ for military actors to increasingly behave in ways that challenge and in some cases violate the central principles of civil-military relations. 

The chapter consists of three parts. The chapter first explains and defends both the methodology employed and the original data set examined in the chapter. The second and main part of the chapter presents, analyzes, and interprets the data. The final part of the chapter concludes by addressing the limitations of the empirical findings and exploring alternative explanations for the patterns that are uncovered in the analysis.  

## Methodology

The methodological approach employed in this chapter consists of three steps. The first is to examine all available instances of opinion commentary authored by military actors over a finite period of time. This will involve the collection of original data, which I describe later.  After the data are collected, the second methodological step is to determine those instances of opinion commentary authored by retired military actors that constitute violations of the central principles of civil-military relations. The final step in the methodological process involves conducting a statistical analysis that allows the researcher to control for any relevant variables that may reasonably impact suspected variations in the data. Because we are examining one type of political behavior undertaken by military actors, following this three-step methodological process helps evaluate the first two hypotheses presented in the previous chapter, H1 and H2.   

_H1: Military actors increasingly violate the central principles of civil-military relations when polarization is high relative to periods of low polarization._ 

_H2: Military actors increasingly violate the central principles of civil-military relations in public and visible ways when military prestige is high relative to periods of low military prestige._ 

The time range of the data explored in this chapter spans from 1979-2020, a period of just over four decades. Over this timeframe, the levels of both of the independent variables --- polarization and military prestige --- vary quite a bit, which enable the researcher to undertake a thorough examination of the roles, if any, of these variables. For instance, in 1979, the scaled value (using DW-NOMINATE scores) of polarization in the US House of Representatives was roughly 59.6, whereas in 2020, the same value was roughly 87.3 [@jeffrey_b_lewis_voteview_2020]. Similarly, the level of military prestige also increased over the same time period. Consider for instance that in 1979, only 54% of Americans surveyed expressed either a "great deal" or "quite a lot" of trust in the nation's military, and in 2020, 72% of those surveyed expressed the same notion [@noauthor_confidence_2020]. The lowest and highest percentage of the American population expressing these levels of confidence in the nation's military across the data are 50% (1981) and 85% (February of 1991)[@noauthor_confidence_2020].^[1991 is the only year in which two data points are given. The level of confidence dropped to 69% by October of the same year, suggesting that the February data point captured an effect related to the Gulf War, which ended in early 1991.] 

The levels of trust in the military and polarization in the US House of Representatives from 1979 - 2020 are displayed in Figure \@ref(fig:polar-trust-oped). Because both of the independent variables examined in this study change during the time period examined in this paper (and in the same direction!), and because the theory predicts that military actors will increasingly violate the central principles of civil-military relations as both variables increase, a systematic investigation of the data will help disentangle the relative impacts of both the levels of polarization and military prestige on opinion commentary written by military actors. 

```{r trust-ch3-prep, include=FALSE, warning=FALSE, echo=FALSE}

df_trust_polar_ch3 <- read_csv("../shareddata/polar-inst-trust-time.csv")

df_trust_polar_ch3 <- df_trust_polar_ch3 %>% select(-Congress) %>% filter(Year<=2020) %>% 
  mutate(
    house_polar_dim1 = house_polar_dim1 *100,
    sen_polar_dim1 = sen_polar_dim1 *100,
    ) %>% pivot_longer(Military:house_polar_dim1, names_to = "value", values_to = "Score") %>% distinct() %>% na.omit() 
```

```{r polar-trust-oped, include=T, echo=F, warning=FALSE, message=F, fig.height=4, fig.width=6, fig.cap = "Public Trust (L) and Polarization (R), 1979-2020" }

# Note: this is the first of many adjusted graphs from my dissertation. 
# These changes mainly transform any colored graphs into a black and white graph. 
# Here, note that instead of calling the function "color" within aes(), I call "linetype".  
# This is the main difference in this graph versus the dissertation chapter 3 graph. 

df_trust_polar_ch3 %>%  ggplot(aes(x = Year, y = Score, linetype = value)) +
  geom_line() +   
  geom_point(size = 0.7) +   
  labs(x = "Year", y = "Trust in Institutions") +
  scale_linetype_manual(values = c("Military" = "solid", "house_polar_dim1" = "dashed"), name="Trust;\nPolarization",
                         breaks=c("Military",  "house_polar_dim1"),
                         labels=c("Trust In\nMilitary","US House\nPolarization")) + 
  scale_y_continuous(sec.axis = sec_axis(~., name = "Polarization (Scaled)")) + 
theme(legend.position = "bottom")

```


### Why Explore Opinion Commentary Authored by Retired Military Officers? 

We should also briefly pause to consider why an examination of the specific behavior of written opinion commentary authored by retired military officers is of not just theoretical, but also of methodological value. For starters, recall from the previous chapter that the political behaviors available to military actors exist along a spectrum that ranges in severity, or in risk to violating one of the central principles of civil-military relations. The previous chapter specifically claimed that authoring opinion commentary is a type of political behavior available to military actors that need not violate _any_ of the central principles of civil-military relations, and thus, that the act of authoring opinion commentary was different from other political behaviors, such as explicit insubordination and endorsing political candidates at political conventions (a form of politicking), that by definition violate one or more of these principles. 

To know if opinion commentary authored by retired military officers actually violates the principles of civil-military relations, we therefore need to know more details about the commentary. Specifically, what does the content actually say, and what message does it convey? Only then can the researcher determine if a published  opinion piece authored by a military actors upheld the principles of civil-military relations.  

Furthermore, written opinion commentary contains two intrinsic advantages from a research perspective compared to other forms of commentary, such as television or radio interviews, or even pieces published on personal social-media accounts. The first advantage is that written opinion pieces, especially those intended for publication in a major newspaper, are deliberately intended for consumption by a wide public audience. While social media postings and television or radio interviews may certainly end up in the public eye and perhaps even reach a wider audience than published newspaper articles, my point here is that there is nonetheless a qualitative difference between commentary published in a major newspaper versus through other outlets in that the author of a published opinion piece must craft a deliberate and intentional message. These often take the form of an argument that addresses a pressing topic or issue. I do not doubt that many high profile leaders similarly craft social media posts deliberately, but the simple fact is that they all do not. Moreover, what is indisputable is that unlike posting to a personal social media account, publishing an op-ed in a major newspaper can not only be a very competitive process, but it also requires editorial review. Indeed, it is not uncommon to see opinion pieces in the most prominent of major US newspapers published by heads of state, members of Congress, and leaders of industry and academia. 

Therefore, a second advantage of examining written opinion editorials versus other types of opinion commentary is that the author's intent is likely to be clearly discernible, whereas that may not be the case in other forms of commentary. Television and radio interviews may certainly offer glimpses into the personalities of whomever is speaking, but they are also venues that may increase the chance that a retired officer either misspeaks, or is later misquoted out of context.^[For this reason, I do not include examining published interviews with retired military officers, nor short forms of analysis, such as the "Monkey Cage" featured in _The Washington Post_ (retired and active military officers are featured in or author "Monkey Cage" analysis somewhat regularly.] A written op-ed or letter to the editor, on the other hand, must be carefully crafted, from start to finish, to convey an argument that is intended to persuade the reader. 

Focusing on the commentary authored by retired versus active-duty military actors similarly provides important methodological advantages. To begin with, it is reasonable to conclude that retired military officers are more likely to publish opinion commentary than their active-duty counterparts. Though this claim cannot be supported empirically, it is logical to conclude that many active-duty military officers are deterred from publishing opinion pieces altogether. This claim flows from the fact that while there are no express prohibitions that prevent active-duty service members from publishing opinion pieces altogether, active-duty military nonetheless face greater scrutiny when doing so than retired military personnel.^[For example, Department of Defense Directive 1344.10 (February 2008) indicates that while active duty members of the Armed Forces may "write a letter to the editor of a newspaper expressing the member's personal views on public issues or political candidates" so long as "the letter clearly states the views expressed are those of the individual only and not those of the Department of Defense," the same directive also expressly prohibits active service members from "allowing or causing to be published partisan political articles, letters, or endorsements signed or written by the member that solicits votes for or against a partisan political party, candidate, or cause." See @department_of_defense_political_2008 for more.] Retired officers do not face the same formal restrictions. Finally, it is reasonable to conclude that active-duty military officers may simply not have the time to craft personally-written commentary. The most senior active military are in demanding jobs, particularly those serving at the Flag / General officer rank. Retired military actors are not sitting on their hands idle, but it is likely that as a collective body, they have more time on their hands during which they could craft a deliberate message for publication in a major media outlet.  
A second methodological advantage involves the issue of variance, or variety. My claim here flows from the first advantage --- that is, because retired military officers are _more likely_ to publish opinion commentary than their active-duty counterparts in the first place, there will correspondingly be a greater variety in what they publish (relative to active duty military actors), because retired military actors themselves embody greater variety in terms of their ages and experiences. To see this, we can compare the ages and experience levels writ large of active-duty military versus retired military actors at any given _snapshot in time_. Active-duty senior military officers, at any point in time, are generally those with between 30 and 40 years of service, and thus are likely to vary within 10 years of age from each other (plus or minus a few years, depending on how old an actor was when he or she joined the military or became an officer). On the other hand, the retired senior military officer community, at any point in time, includes not only those who had very recently retired, but also those who have retired two or even three (or more, depending on how old they are!) decades previously. My point here is that while the active and retired military actors communities served in the same profession, they did so at different points in time. This matters because whereas active-duty military officers at any point in time possess recent experience as a senior military officer serving under one or two different presidential administrations and former defense secretaries, the collective experience of the retired senior military officer pool likely spans far more, perhaps upwards of five or six presidents and defense secretaries. These characteristics of retired senior military actors --- that they are more likely to publish and that they possess a wider range of collective experience than the active-duty military actor pool --- suggest that retired senior military actors will publish an altogether wider body of articles that are informed by different perspectives, opinions, and stances than their active-duty counterparts.  

Two final things about retired senior military actors must be said. The first is that the words spoken by retired military officers, and especially those who reached the most senior in ranks while on active-duty, still carry significant weight. In fact, the conventional wisdom is that retired military officers, especially retired generals and admirals, still speak for the institution, or are certainly perceived to do so, even in retirement. The historian Richard Kohn once remarked, for instance, that "retired general and flag officers are analogous to the cardinals of the Roman Catholic Church" [Richard Kohn as cited in @owens_rumsfeld_2006, 70]. This is important, because though they may not be expressly required to submit the same disclaimer in the publication as active-duty actors, as noted above, retired military actors nonetheless still think before they speak. Second, from a methodological standpoint, any perceived difference between active-duty and retired military actor publication habits becomes less important when we consider the fact that in this chapter, the focus is only on what retired military actors publish. By holding the actor type constant and by only examining retired military actors and what they say, we are in a good position to detect potential variation and to investigate what is driving these changes.    

### The Data

The data consist of all op-eds or letters to the editor (391) whose authors identify as retired or former military officers and published between 1979 - 2020 in a total of five major US newspapers: _The Wall Street Journal_ (WSJ), _The New York Times_ (NYT), _The Washington Post_ (WaPo), _The Los Angeles Times_, and _The USA Today_. With the exception of _The USA Today_, all of the newspapers have long and established histories (the _USA Today_ began in 1982 [@noauthor_about_nodate]). Furthermore, three of the five newspapers in particular -- the _The Wall Street Journal_ (WSJ), _The New York Times_ (NYT), and _The Washington Post_ (WaPo) -- are likely the most circulated among the defense and national security communities, as they are located in New York City and Washington D.C., respectively, where a significant number of prominent think tanks, international organizations, and the Pentagon are based. Thus, these newspapers together constitute both a fairly wide and likely "net" into which retired senior military actors may seek to publish their viewpoints. 

To obtain the observations, I use a series of key-word searches in several different online databases.^[These include Factiva, Lexus-Uni, and ProQuest Historical Newspapers.] These searches look for words that would appear in the article byline describing the author of the piece, such as "retired military officer," "former General," "former Admiral," etc.^[Please see this paper's Appendix for the exact search parameters used to collect the data. So far as I know, this data constitutes the entirety of opinion commentary published in these newspaper sources over the time period examined. The data were assembled by the author from 2019-2021.] In some instances, especially when the same retired military officer authored or co-authored multiple publications within the data, the officer did not in every case refer to himself or herself as a retired military officer.^[This occurred especially when an officer had been appointed to a high-level government civilian position. For example, Army General Barry McCaffrey served as President Clinton's Director of the Office of National Drug Control Policy after retiring from the Army. However, because members of the public might recognize authors such as McCaffrey as a prominent retired military figure, and not only as a governmental appointee, I include in the data pieces authored by those officers who were serving in a civilian government role at the time an opinion piece was authored.] In these instances, I simply institute a control for whether the author self-identifies as a retired military officer in the publication.^[Overall, there were two main challenges in collecting the data. The first was that not all retired military officers clearly identify themselves as such. For instance, some op-eds introduced authors not by their rank, but by the organizational position that the author formerly held, such as "Former Commander of US Central Command." In many cases, this required further investigation of a biographical nature to conclusively determine whether the author was in fact a retired military officer. The second challenge was that each of the databases used to collect the data organizes and classifies historical newspaper articles somewhat differently. Some databases include editorials as a stand-alone source type to search for, making the acquisition of data easier. Other databases did not, which resulted in completing a more exhaustive search of a much larger set of potential articles to sift through. Of note, I include in the data both opinion articles and letters to the editor regardless of whether these were published in print or online, but count identical articles published in both mediums only once, even if the online and print versions contain somewhat different titles (sometimes they do).]

```{r introduction, include = FALSE}

# Read in the Data

dataset <- read_csv("../shareddata/ch3MilEditorialsfinal.csv")
# Only read in the first 391 rows - row 392 is full of N/A data?
dataset %>% summary()

# Replace NA with 0 in the data for variables letter_ed to online_only, and leg_act #to role
adjdataset <- dataset[1:391,] %>%
  mutate_at(
    .vars = vars(letter_ed:online_only, Leg_Act:Role),
    .funs = ~ case_when(is.na(.) ~0, TRUE ~ 1)
) %>% mutate(
    PubYr = lubridate::year(PubDate),
    HostCasRate=case_when(
      PubYr==1979~0,
      PubYr==1981~0,
      PubYr==1982~.094669,
      PubYr==1983~13.23,
      PubYr==1984~.327356,
      PubYr==1985~.2325,
      PubYr==1986~.0918,
      PubYr==1987~1.8,
      PubYr==1988~.8012,
      PubYr==1989~1.0889,
      PubYr==1990~.04885,
      PubYr==1991~7.5619,
      PubYr==1992~.056369,
      PubYr==1993~1.731,
      PubYr==1994~0,
      PubYr==1995~.4659,
      PubYr==1996~1.3733,
      PubYr==1997~0,
      PubYr==1998~.21722,
      PubYr==1999~0,
      PubYr==2000~1.2387,
      PubYr==2001~4.188,
      PubYr==2002~1.204648526,
      PubYr==2003~21.92014883,
      PubYr==2004~52.08012261,
      PubYr==2005~53.62790218,
      PubYr==2006~56.06864727,
      PubYr==2007~61.97806503,
      PubYr==2008~25.10292556,
      PubYr==2009~24.33760906,
      PubYr==2010~31.86616212,
      PubYr==2011~31.313254,
      PubYr==2012~21.49178707,
      PubYr==2013~8.67877259,
      PubYr==2014~4.034406012,
      PubYr==2015~1.750460447,
      PubYr==2016~1.229532132,
      PubYr==2017~1.76745244,
      PubYr==2018~1.075840616,
      PubYr==2019~1.799775028,
      PubYr==2020~1.121495327,),
    HostCasRateLagged=case_when(
      PubYr==1979~0,
      PubYr==1981~0.438862,
      PubYr==1982~0,
      PubYr==1983~.094669,
      PubYr==1984~13.23,
      PubYr==1985~.327356,
      PubYr==1986~.2325,
      PubYr==1987~.0918,
      PubYr==1988~1.8,
      PubYr==1989~.8012,
      PubYr==1990~1.0889,
      PubYr==1991~.04885,
      PubYr==1992~7.5619,
      PubYr==1993~.056369,
      PubYr==1994~1.731,
      PubYr==1995~0,
      PubYr==1996~.4659,
      PubYr==1997~1.3733,
      PubYr==1998~0,
      PubYr==1999~.21722,
      PubYr==2000~0,
      PubYr==2001~1.2387,
      PubYr==2002~4.188,
      PubYr==2003~1.204648526,
      PubYr==2004~21.92014883,
      PubYr==2005~52.08012261,
      PubYr==2006~53.62790218,
      PubYr==2007~56.06864727,
      PubYr==2008~61.97806503,
      PubYr==2009~25.10292556,
      PubYr==2010~24.33760906,
      PubYr==2011~31.86616212,
      PubYr==2012~31.313254,
      PubYr==2013~21.49178707,
      PubYr==2014~8.67877259,
      PubYr==2015~4.034406012,
      PubYr==2016~1.750460447,
      PubYr==2017~1.229532132,
      PubYr==2018~1.76745244,
      PubYr==2019~1.075840616,
      PubYr==2020~1.799775028,
      PubYr==2020~1.121495327,)
) %>% print()

summary(adjdataset)
names(adjdataset) 

# count the number of observations by type of binary variable and store as new dataframe
countbytype  <- adjdataset %>% mutate(
    Topic=case_when(
      Topic=="Support" ~ "Support",
      Topic=="Warfighting" ~ "Warfighting/Operations",
      Topic=="ForeignPolicy" ~ "Foreign Policy",
      Topic=="BdgtWpnsTrps" ~ "Budget, Weapons, Troops",
      Topic=="DomesticPolicy" ~ "Domestic Policy",
      Topic=="CivMilBalance" ~ "Civil-Military Relations",
      Topic=="ServiceCulture" ~ "Service Culture",
      Topic=="SocialPolicy" ~ "Social Policy"
    )
  ) %>% count(Topic)

# count the number of observations by source
countbysource <- adjdataset %>% 
  count(Source) %>% print()

#count the number of times each source occurs in the data
WSJcount <- adjdataset %>% count(Source=="WSJ") %>% print()
NYTcount <- adjdataset %>% count(Source=="NYT") %>% print()
WaPOcount <- adjdataset %>% count(Source=="WaPO") %>% print()
USATodaycount <- adjdataset %>% count(Source=="USA Today") %>% print()
LATimescount <- adjdataset %>% count(Source=="LA Times") %>% print()

# Create a new variable called Yrcount, which is a count of the yearly number of published op-eds

adjdataset <- adjdataset %>% 
  group_by(PubYr) %>% 
  mutate(Yrcount=n()) %>% 
  print()


# number of authors and author teams
adjdataset %>% 
  group_by(Author) %>% 
  count() %>% 
  print()
```

## Analysis

This main and second section of the chapter analyzes and interprets the data. This section will first present the data to help orient the reader. This section will then undertake a deeper statistical exploration of the data that generally consists of answering two main questions. The first involves the general topics that retired military officers have addressed through the opinion commentary they publish. That is, we will determine what topics they are writing about. The second question will then get at the heart of what this chapter is after, which is to determine whether the commentary that retired military actors has published adheres to the central principles of civil-military relations, to what degree, and why. After investigating these two questions, this section of the chapter interprets the data. 

The data set includes a total of 391 observations written by a total of 217 distinctly different authors or author teams. Eight of these observations were written by anonymous authors. Included in the data also are cases in which at least one retired military officer co-authored a piece with one or more civilian authors.^[There are several co-authored pieces. For example, where General (Retired) David Petraeus wrote one publication and another one was written by General (Retired) David Petraeus and Michael O'Hanlon, I count these as two different authors for coding purposes.] There are also several authors who penned multiple observations. The most prolific of these officers include Retired Army Lieutenant General William Odom (22 publications in total), Retired Air Force General Michael Hayden (20 publications in total), and Retired Marine Lieutenant Colonel Robert McFarlane, who later served as President Reagan's National Security Adviser (18 publications). 

### Summary Statistics
```{r, include=FALSE, echo=FALSE}
# show summary stats for yearly count, rank, and then a breakdown according to source
# yearly count
yearstats <- adjdataset %>% 
  select(PubYr, Yrcount) %>% 
  distinct(PubYr, Yrcount) %>% 
  print ()


# create an observation for 1980 to handle the year in which there were/are no observations in 1980
Obs_1980 <- data.frame(1980, 0)      
#Naming the missing Data Frame - Step 2  
names(Obs_1980) <- c("PubYr", "Yrcount")  
#Using rbind() function to insert above observation  
yearstats <- rbind(yearstats, Obs_1980)


summary(yearstats)
sd(yearstats$Yrcount)
var(yearstats$Yrcount)

#rank
rankstats <- adjdataset %>% 
  filter(AuthRank <=10) %>% 
  select(Author, AuthRank) %>% print()

summary(rankstats)
sd(rankstats$AuthRank)
var(rankstats$AuthRank)

#sex
adjdataset %>% group_by(AuthSex) %>% count()

#service
adjdataset %>% group_by(Service) %>% count()

Descriptive_Stats <- tribble(
  ~Variable, ~Min, ~Max, ~Mean, ~SD, ~N, 
  'Author Rank', 4, 10, 8.36, 1.95, 391,
  'Number of Yearly Publications', 0, 27, 9.31, 6.93, 391)

Sex_Stats <- tribble(~Breakdown, ~Observations, ~Percentage,
   'Male Authors', 375, 95.9,
  'Female Authors', 3, .8,
  'Mixed  Authorship', 5, 1.3,
  'Gender Unknown', 8, 2,)
  
Service_Stats <- tribble(~Breakdown, ~Observations, ~Percentage,
  'Army', 206, 52.7,
  'Navy',  56, 14.3,
  'Marine Corps', 47, 12.0,
  'Air Force', 63, 16.1,
  'Coast Guard',3,.8,
  'Mixed Service Authorship', 16, 4.1)
  

 rankdistrib <- adjdataset %>% group_by(AuthRank) %>% count()
 rankdistrib_scaled <- rankdistrib %>% 
   mutate(
     Rank=case_when(
       AuthRank== 4 ~ "4: Major/Lieutenant Commander",
       AuthRank== 5 ~ "5: Lieutenant Colonel/Commander",
       AuthRank ==6 ~ "6: Colonel/Captain",
       AuthRank ==7 ~ "7: Brigadier General/Rear Admiral (Lower Half)",
       AuthRank == 8 ~ "8: Major General/Rear Admiral (Upper Half)",
       AuthRank ==9 ~ "9: Lieutenant General/Vice Admiral",
       AuthRank == 10 ~ "10: General/Admiral",
       AuthRank == 11 ~ "Unknown"
     ), 
     Rank=fct_relevel(Rank, "4: Major/Lieutenant Commander", "5: Lieutenant Colonel/Commander", "6: Colonel/Captain", "7: Brigadier General/Rear Admiral (Lower Half)", "8: Major General/Rear Admiral (Upper Half)", "9: Lieutenant General/Vice Admiral", "10: General/Admiral", "Unknown")
   )
 
 

```

In addition to capturing the publication date and the source in which commentary piece is published, I record and include several pieces of biographical information about each author. This includes the branch of military service of the author, the rank achieved by the author during his or her time in service, and the gender of the author. Summary statistics for the variables of author rank and the annual count of publications are displayed in Table \@ref(tab:desc-stats). The variable for author rank is coded equivalently to the officer's military pay grade.^[For example, a rank of "10" means the officer achieved the pay grade of O-10, or four star general or admiral, the highest rank that an officer can achieve in the contemporary military. A rank value of "7" denotes a one star general or admiral. A rank of "4" corresponds to a pay grade of O-4, which in the Army, Air Force, and Marine Corps, refers to the rank of Major. In the Navy and Coast Guard, a pay grade of O-4 refers to the rank of Lieutenant Commander. A rank of 5 in the Army, Air Force, and Marine Corps refers to a Lieutenant Colonel, whereas in the Navy and Coast Guard, a rank of "5" denotes a Commander. A rank of "6" in the Army, Air Force, and Marine Corps refers to a Colonel, whereas in the Navy and Coast Guard, a rank of 6 corresponds to the rank of Captain.] The ranks of retired military officers in the data set range from an O-4 (Major or Lieutenant Commander) to O-10 (four star general or admiral), and the range of annual number of publications spans from 0 to 27 (In 1980 only, there were 0 publications). 
```{r desc-stats, echo=FALSE, include=TRUE, warning=FALSE, error=FALSE}
T1 <- kable(Descriptive_Stats, 
            format = 'simple', 
            booktabs = TRUE, 
            caption = "Descriptive Statistics for Author Rank and Yearly Number of Publications Breakdown of Observations by Author Sex and Service Affiliation",
            align = c('l', 'c', 'c', 'c'),
            digits = 2)

T1
```

Table \@ref(tab:sex-stats) and Table \@ref(tab:service-stats) show the breakdown of observations by author sex and service affiliation, respectively. Mixed Authorship in Table \@ref(tab:sex-stats) refers to publications that were authored by a mixture of male and female authors, whereas Mixed Service authorship in Table \@ref(tab:service-stats) denotes publications that were authored by a team that had served in multiple service branches (for example, a retired Colonel who had served in the Air Force and a retired Admiral who had served in the Navy write an op-ed together). 
```{r sex-stats, echo=FALSE, include=TRUE, warning=FALSE, error=FALSE}
T2 <- kable(Sex_Stats, 
            format = 'simple', 
            booktabs = TRUE, 
            caption = "Breakdown of Observations by Author Gender",
            align = c('l', 'c', 'c', 'c'),
            digits = 2)

T2
```

In terms of the genders of the author, male authors comprise the bulk of the sample (95.9%). Because the sample includes publications dating back to 1979-2020, a probable reason for this is the difference in gender at the highest ranks of service --- a feature that will likely change in the future as the restrictions on women serving in combat occupational specialties have been removed, and as women increasingly advance to senior ranks and positions. 

Additionally, retired military officers who served in the Army comprise the largest segment (52.7%) of authors in the sample, as Table \@ref(tab:service-stats) shows. Authors who served in the Navy and Air Force comprised 14.3% and 16.1% of the sample, respectively. Representation from authors who served in the Marine Corps (12%) and Coast Guard (.8%) round out the sample. There is little theoretical importance of including the service breakdown except to initially observe whether any obvious disparities appear.^[If such a disparity were to exist, such as 90% of the authors are Air Force veterans, we would have to examine whether there is something unique about service in the Air Force that drives veterans of that particular service to write op-eds in major newspapers.] These percentages somewhat correspond to the relative size of each service in comprising the active duty military. In 2018, for instance, the Army comprised 35% of the active duty force; the Navy, 24%; the Air Force, 24%, the Marine Corps, 14%, and the Coast Guard, 3% [@noauthor_demographics_2020]. But it is difficult to state with certainty that Army authors are over-represented in the sample, and that Coast Guard officers are underrepresented, mainly because the relative sizes of the military services change over time. Particularly when large land wars are fought, such as during Vietnam and the Gulf War, the Army tends to grow. 

```{r service-stats, echo=FALSE, include=TRUE, warning=FALSE, error=FALSE}
T3 <- kable(Service_Stats, 
            format = 'simple', 
            booktabs = TRUE, 
            caption = "Breakdown of Observations by Author Service Affiliation",
            align = c('l', 'c', 'c', 'c'),
            digits = 2)

T3
```


Figure \@ref(fig:rank-pubs) displays the distribution of publications by author rank. The plot shows that publications tend to be authored by those of a higher rank --- 185 of the 391 publications (47.3%) were authored by retired four star generals or admirals. Additionally, 277 of the total 391 publications (70.8%) were authored by generals or admirals (one-, two-, three-, or four-star flag officers). The fact that high ranking officers tend to publish in the newspapers examined is unsurprising and confirms the competitive nature of publishing an opinion piece in one of the premier newspapers in the nation. At the same time, there are enough authors who are not retired generals or admirals (29.2%) to show that those who do not attain the highest ranks still have a respectable opportunity to publish their views in the examined sources. 

```{r rank-pubs, include=TRUE, echo=FALSE, warning=FALSE, fig.cap="Opinion Pieces authored by Retired Military Officers Broken Down by Author Rank, 1979-2020", fig.height=4.5, fig.width=6}
colplot1 <- ggplot(data=rankdistrib_scaled, aes(x=Rank, y=n)) + labs(x="Author Pay Grade / Rank", y="Number of Publications") + geom_col() + geom_text(aes(label=n), position=position_dodge(width=.9), vjust=-.25)+ theme(axis.text.x = element_text(angle=90)) + scale_x_discrete(labels=wrap_format(18))

colplot1

```

The distribution of the data according to newspaper source is displayed in Figure \@ref(fig:source-pubs). The data shows that the overwhelming number (380, or 97.2%) of opinion publications were authored by retired military officers in the _New York Times_, _Washington Post_, or _Wall Street Journal._ Only 11 of the 391 publications (2.8%) were authored in either the _USA Today_ or the _Los Angeles Times_.  This is not surprising. Not only are the former three newspapers among the most prestigious and most circulated across the world, but they are based in the nation's capital and New York City, where think tanks, international organizations, and government offices are highly concentrated.

```{r source-pubs, include=TRUE, echo=FALSE, warning=FALSE, fig.cap= "Opinion Pieces Authored by Retired Military Officers Broken Down by Newspaper Source, 1979-2020", fig.width=4, fig.height=3.1}

colplot2 <- ggplot(data=countbysource, aes(x=Source, y=n)) + labs(x="Source", y="Number of Publications") + geom_col() + geom_text(aes(label=n), position=position_dodge(width=.9), vjust=-.25) + expand_limits(y=160)

colplot2

```

Finally, Figure \@ref(fig:year-count) displays the annual count of publications authored by retired military officers across the dataset. The dashed line represents the annual count after a smoothing function accounts for localized trends in the data. We can observe from this dashed line that on average, the yearly count of publications rose moderately from 1979 until the late 1990s, when the annual count then held steady until the early 2000s. From approximately 2004 until 2020, the average annual count has risen. Interestingly, the solid black line that denotes the actual (rather than the average, or smoothed) yearly count of publications also shows several peaks and troughs, the most drastic of which occurred between the end and the beginning of the Clinton and Bush and the Obama and Trump administrations, respectively. This could be because, akin to the honeymoon approval ratings that new Presidents tend to enjoy early in their tenure, perhaps retired military actors also are not as inclined to publish opinion commentary in the first year of a President's administration as the President designs and begins to implement policy. What is clear from the data is that to the degree that this could be the case, the actual annual number of opinion commentary pieces published by retired military actors then climbed drastically under both the Obama and Trump (first term) Presidencies. 

```{r year-count, fig.align="center", warning=FALSE, error=FALSE, message=FALSE, include=TRUE, echo=FALSE, fig.cap="Annual Number of Op-Eds and/or Letters to the Editor Authored by Retired Military Officers and Published in Major US Newspapers (WSJ, NYT, WaPo, USA Today, LA Times), 1979-2020", fig.width=6, fig.height=4}
  
# construct a scatter plot with line and smoothing

ggplot(data=yearstats, aes(x=PubYr, y=Yrcount)) + geom_point() + geom_line() + geom_smooth(method="loess", linetype="dashed", color="black") + labs(
  x="Year", 
  y="yearly count", 
  caption="Note: Data as of 1 December 2020"
  ) + scale_x_continuous(limits=c(1979, 2020)) + scale_y_continuous(limits=c(-7, 28)) + 
geom_vline(xintercept = 1981, size=.2, colour="black") + 
  geom_vline(xintercept=1989, size=.2, colour="black") + 
  geom_vline(xintercept=1993, size=.2, colour="black") + geom_vline(xintercept=2001, size=.2, colour="tomato") + 
  geom_vline(xintercept=2009, size=.2, colour="black") +
  geom_vline(xintercept=2017, size=.2, colour="black") +
  geom_text(aes(x=1981, label="Reagan",y=10), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1989, label="Bush 41",y=15), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1993, label="Clinton",y=20), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2001, label="Bush 43",y=-2), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2009, label="Obama",y=-2), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2017, label="Trump 45",y=-2), colour="black", angle=90, vjust=1, text=element_text(size=9)) 
  
```

It is worth briefly pausing to note the breadth of events that have occurred over the time period examined that impacted the military. In terms of external threats and wars, this period includes the final years of the Cold War against the Soviet Union (1989), the Gulf War in Iraq (1990-1991), operations in the Balkans (primarily 1993-1995), and the post-9/11 wars in Iraq (2003 and beyond) and Afghanistan (2001-2021), as well as a host of smaller but important military operations in Grenada (1983), Panama (1989), Somalia (1992-1993), and Haiti (1994-1995). 

The military has also undergone significant social and institutional changes in the time period examined. For example, the late 1970s came just years after the US Government ended the draft (1973). The debates over the "Don't Ask, Don't Tell" policies, instituted in 1994 before being repealed in 2011, are also captured in the data set, along with numerous other social debates that have involved the military, including opening up combat arms branches to women (2014-2015) and debates over the inclusion of transgender troops. In short, the period from 1979-2020 has provided plentiful opportunities for retired military officers to share their thoughts with the public through written opinion commentary. 

### What Are Retired Military Officers Writing About?

We want to first examine what topics retired military actors have addressed in their opinion commentary in the data. This requires classifying each of the observations by a topic area. Because historical and contextual circumstances change over time, however, this requires developing a possible range of topics that is both broad enough to classify every observation, yet sufficiently narrow to generate a meaningful comparison of topics across the time period. I therefore develop a categorical variable for topic that can take one of eight possible values as shown in Table \@ref(tab:topic-scheme).^[Classifying each observation into one of the eight possible topics requires some judgement. Some observations in the data address multiple topics, but I classified each observation only according to one topic category. To assist in determining the primary topic addressed in each publication, I identified what I thought was the opinion piece's thesis statement, and classified the observation accordingly.]

```{r topic-scheme, include=TRUE, echo=FALSE}
topic_categories <- tribble(~Topic, ~Description, ~Examples,
   'Foreign Policy','If the publication primarily addresses American Foreign Policy or overarching National Security Policy', 'A Disaster Puts Putin in a Bind, by William Odom; The Test Ban Solution, by John Shalikashvili',
  'Warfighting and Operations', 'If the publication primarily addresses an ongoing conflict or a central aspect related to the ability of the military to fight and win on the battlefield', 'A Month in Macedonia Will Not Be Enough, by Wesley Clark; A Plan to Save Iraq from ISIS and Iran, by Jack Keane',
  'Social Policy', 'If the publication primarily addresses questions or issues related to who should serve, and/or why', 'Banning Transgender Troops Only Hurts Us, by Mike Mullen; US Military Readiness Requires the Draft, by William Westmoreland',
  'Domestic Policy', 'If the publication primarily addresses issues that do not have an immediate and direct impact on the military, or that describe the general operating atmosphere and political conditions in Washington D.C.', 'The Travel Ban Hurts American Spies - and America, by Michael Hayden; Our Republic is Under Attack from the President, by William McRaven',
  'Budget/Weapons/Troops', 'If the publication primarily addresses issues such as defense budgets, a particular weapons system, or troop benefits/pay', 'Washington Tightwads are Creating a Hollow Military, by Gordon Sullivan; We Need More Troops, by Barry McCaffrey',
  'Support', 'If the publication primarily makes general or specific calls of support for the military or for particular military or defense figures', 'In Defense of Donald Rumsfeld, by John Crosby and Thomas McInerney; From Forward Operating Base to Boardroom, by Stanley McChrystal',
  'Civil-Military Relations', 'If the publication primarily addresses how military and civilians can better interact and relate to each other, or discusses how organizations and departments can be best structured to offer advice to civilian leaders, issues of strategy, etc.', 'Who Decides When We Go to War, by David Barno; Military Leaders Do Not Belong at Political Conventions, by Martin Dempsey',
  'Service Culture', 'If the publication primarily addresses an ongoing issue - positive or negative - that is occurring within the military itself and that bears on the internal culture of the military', 'Yet Another Insult to Women, by Wayne Johnson; The Navys Blues, by David Evans',)


  kable(topic_categories, booktabs=T, caption="Categorical Values of the Topic of Retired Military Officer Public Commentary") %>%
  kable_styling(full_width = F, font_size=11, latex_options="striped") %>% 
  column_spec(1, width="10.5em") %>% 
  column_spec(2:3, width="16em") 
```

Table \@ref(tab:pub-subject) displays the breakdown of observations by topic. The topics of _Warfighting and Operations_ and _Foreign policy_ account for a total of 230 of the 391 observations (58.8% of the total sample). The categories of _Support_, _Domestic Policy_, and _Budget/Weapons/Troops_ account for a total of 120 observations, or 30.7% of the sample. Finally, the topics of _Social Policy_, _Civil-military Relations_, and _Service Culture_ combined account for the remaining 41 observations, or 10.5% of the sample. 

```{r pub-subject, fig.align="center", include=TRUE, echo=FALSE, warning=FALSE}
countbytype %>%
  kable(format="latex", caption="Publication Breakdown by Subject") %>%
  kable_styling(latex_options = "striped", font_size=10) %>% 
  row_spec(0, bold=T)
```


```{r topic-counts-props, include=FALSE, echo=FALSE}

# I create several variables that count the number
# and proportion of articles by topic type. 

adjdataset <- adjdataset %>% group_by(PubYr) %>% 
  mutate(
    dom_pol_count=sum(Topic=="DomesticPolicy"),
    dom_pol_prop=(dom_pol_count/Yrcount),
    war_count=sum(Topic=="Warfighting"),
    war_prop=(war_count/Yrcount), 
    fp_count=sum(Topic=="ForeignPolicy"),
    fp_prop=(fp_count/Yrcount),
    soc_pol_count=sum(Topic=="SocialPolicy"),
    soc_pol_prop=(soc_pol_count/Yrcount), 
    bud_count=sum(Topic=="BdgtWpnsTrps"),
    bud_prop=(bud_count/Yrcount),
    spt_count=sum(Topic=="Support"),
    spt_prop=(spt_count/Yrcount),
    civ_mil_count=sum(Topic=="CivMilBalance"),
    civ_mil_prop=(civ_mil_count/Yrcount),
    svc_cul_count=sum(Topic=="ServiceCulture"),
    svc_cul_prop=(svc_cul_count/Yrcount)
  ) 


# Prepare this data for graphing, below. 
topic_graph_df <- adjdataset %>% 
  select(PubYr, dom_pol_prop, war_prop, fp_prop, soc_pol_prop, bud_prop, spt_prop, civ_mil_prop, svc_cul_prop) %>% pivot_longer(dom_pol_prop:svc_cul_prop, names_to = "statistic", values_to = "Proportion") %>% distinct () %>% print()

# build the graph
topic_graph <- topic_graph_df %>% ggplot(aes(x=PubYr, y=Proportion, linetype=statistic, color=statistic)) + 
  geom_smooth(aes(size=statistic), se=FALSE) + 
  labs(x="Year", y="Proportion of Commentary by Topic") + 
  scale_linetype_manual(values= c("solid", "solid", "solid", "dotted", "dotted", "dotted", "solid", "solid"), name="Topic",
                         breaks=c("bud_prop", "civ_mil_prop", "dom_pol_prop", "fp_prop", "soc_pol_prop", "spt_prop", "svc_cul_prop", "war_prop"), labels=c("Budget/Weapons/Troops", "Civil-Military Relations","Domestic Policy", "Foreign Policy","Social Policy", "Support", "Service Culture", "Warfighting"), ) +
  scale_color_manual(values =c("black", "gray75","white", "black", "gray75", "white", "black", "gray75"), name="Topic",
                         breaks=c("bud_prop", "civ_mil_prop", "dom_pol_prop", "fp_prop", "soc_pol_prop", "spt_prop", "svc_cul_prop", "war_prop"), labels=c("Budget/Weapons/Troops", "Civil-Military Relations","Domestic Policy", "Foreign Policy","Social Policy", "Support", "Service Culture", "Warfighting"))+
  scale_size_manual(values=c(.8, .8, 2, 1.3, 1.3, 1.3, 2, 2), name="Topic",
                         breaks=c("bud_prop", "civ_mil_prop", "dom_pol_prop", "fp_prop", "soc_pol_prop", "spt_prop", "svc_cul_prop", "war_prop"), labels=c("Budget/Weapons/Troops", "Civil-Military Relations","Domestic Policy", "Foreign Policy","Social Policy", "Support", "Service Culture", "Warfighting"))+
  theme(legend.position="bottom", panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  geom_vline(xintercept = 1981, size=.2, colour="black")+
  geom_vline(xintercept=1989, size=.2, colour="black") + 
  geom_vline(xintercept=1993, size=.2, colour="black") + geom_vline(xintercept=2001, size=.2, colour="black") + 
  geom_vline(xintercept=2009, size=.2, colour="black") +
  geom_vline(xintercept=2017, size=.2, colour="black") +
  geom_text(aes(x=1981, label="Reagan",y=.42), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1989, label="Bush 41",y=.35), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1993, label="Clinton",y=.35), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2001, label="Bush 43",y=.25), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2009, label="Obama",y=.3), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2017, label="Trump 45",y=.4), colour="black", angle=90, vjust=1, text=element_text(size=9)) 

```

This breakdown of observations by topic type is not necessarily surprising. Based on the experiences and expertise of retired military officers, we would reasonably expect that this type of military actor would address matters that relate to _Warfighting and Operations_ and _Foreign Policy_ often. After all, many retired military officers are veterans of wars, and have served in significant positions of responsibility within government. However, a rather interesting picture emerges when I trace the proportion of each topic area addressed over time using smoothed trend lines. This is displayed in Figure \@ref(fig:topics-time). 


```{r topics-time, include=TRUE, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.cap="Proportion of Opinion Publications authored by Retired Military Officers by Topic Area, 1979-2020", fig.height=4.5, fig.width=6}

topic_graph

```

Figure \@ref(fig:topics-time) shows that since 1979, the proportion of three of the eight topic areas authored by retired military officer commentary annually has varied significantly. First, the proportion of retired military officer commentary that addressed topics related to foreign policy (black dashed line) was relatively high throughout the late 1980s and early 1990s, but then dropped continually until approximately 2011, after which it began to rise again. Second, the proportion of commentary addressing warfighting (thick gray line) each year increased throughout the 1990s, but began to decline around 2008, and declined even more drastically until 2020. Finally, note that the proportion of topics addressing domestic policy (solid white line) each year has risen sharply since about 2010. For the 31 years prior to that, the proportion of commentary addressing domestic policy each year never climbed above 10 percent, whereas at the end of the data range, in 2020, the proportion is nearly 35%. 

We should certainly expect some variance in the topics retired military officers address. For example, the nation is not always engaged in a war, and when they do occur, they range in terms of their intensity, the number of casualties that are inflicted, and a host of other factors. Thus, we might reasonably expect a relative spike in topics that address warfighting/operations or foreign policy, for example, when a war or a major foreign policy crisis is unfolding or ongoing. We can clearly see this unfold in Figure \@ref(fig:topics-time). For example, the proportion of commentary addressing topics related to warfighting and operations (gray dot-dashed line) peaked around 2007, which coincided with a massive US Troop surge to Iraq. Topics addressing matters of foreign policy (black dashed line) peaked in the early 1990s, coinciding with multiple crises that developed in the Balkans, Haiti, and Somalia after the end of the Cold War.

But other variation displayed in Figure \@ref(fig:topics-time) seems to suggest that something deeper than a cycle of war and peace are at play. This is especially true when we observe what happens in 2010 and beyond in Figure \@ref(fig:topics-time). We see clearly that prior to Donald Trump assuming the Presidency for his first term in 2017, the highest relative proportion of commentary authored by retired military officers in a given year addressed topics related to warfighting (gray dot dashed line) and foreign policy (black dashed line), even as the proportion of commentary addressing topics related to domestic policy (thick white line) was rising. Throughout the Trump Presidency, however, the topic that retired military officers have addressed most has been domestic policy. It is not a stretch to say that partway through President Trump's first term in office, the cadre of our nation's retired military officers were functioning primarily as domestic commentators, rather than as military experts who addressed topics related to foreign policy and warfighting. This finding serves is an initial clue that begs for more analysis. 

To that end, we now turn our attention to conducting a second step in our statistical analysis of the data. That is, we want to identify the degree to which the commentary that US retired military actors published adhered to versus violated the central principles of civil-military relations, and why these violations, if there are any, may have occurred. 

\singlespace
### Does Retired Military Officer Opinion Commentary Violate the Principles of Civil-Military Relations?
\doublespace

In order to measure variation in adherence to the central principles of civil-military relations, I develop three dichotomous indicator variables that capture potential violations of each principle. We can understand this by thinking through how a piece of opinion commentary authored by a retired military officer might actually violate in practice the principles of civilian control of the military, non-partisanship, and non-interference.

I operationalize violations of the principle of civilian control by coding instances in which a retired military officer blatantly criticizes or excoriates a civilian leader. Because the observations are all opinion pieces, and thus somewhat argumentative in nature, my goal is not to simply identify publications which point out shortcomings of policy, or make recommendations for civilian leaders to implement. We would expect most published opinion commentary pieces to do these things. Instead, I operationalize a violation of the principle of civilian control in an opinion piece by identifying content that contains strong, blatant, and direct criticism of a sitting civilian official, and more precisely, the President of the Secretary of Defense, both of whom are in the chain of command of the military. Direct and blatant criticism of a sitting Commander in Chief or a Defense Secretary by a retired military officer undermines the principle of civilian control because engaging in this behavior likely generates a political cost that these civilian leaders then have to contend with. These political costs may be small or large, but their presence alone likely makes it more difficult for the President to enact his intended policy goals [@brooks_crisis_2021]. 

To operationalize a violation to the principle of non-partisanship, I denote instances of opinion commentary that explicitly endorse candidates running for elected office, or that explicitly endorse or rebuke a political party's platform. Commentary authored by retired military actors that express such partisan pronouncements violates the principle of non-partisanship because the author's position conveys his or her partisan affiliation, allegiance, or alignment. This is problematic for a host of reasons, not the least of which is that the American public may wrongfully conclude that the retired officer is speaking on behalf of the military institution.  

Finally, I operationalize violations of the principle of non-interference of the military into certain realms of state policy by looking for commentary in which retired military actors address topics that are indirectly, tangentially, or altogether unrelated to the military or to defense policy. The key question I answer when looking for violations to this principle of non-interference is whether the author's expertise as a retired military officer serves as reasonable credentialing for the author to inform the topic he or she is addressing. 

Two points of clarification about this particular operationalization are worth underscoring.The first is that the roles, responsibilities, and missions undertaken by the military have significantly expanded over the past several decades, both overseas and domestically [@brooks_how_2016]. The US military now plays a prominent role not only in preparing to fight conventional wars, but also in implementing other aspects of America's expansive foreign policy. The US military also routinely provides support to civilian authorities domestically in responding to various types of natural disasters and civil unrest.^[The military's role during the COVID-19 Pandemic has only magnified these tendencies. For example, Operation Warp Speed, the logistics operation designed by the Trump Administration to help manufacture, produce, and deliver a vaccine for COVID-19, has heavily thrust the military into conversation and relationships with the healthcare community, private corporations, and transportation companies. Operation Warp Speed was run, moreover, by an active-duty four-star Army General, Gustave Perna. Some civil-military relations scholars have expressed concerns that placing the military in charge of this operation has had, at times, the unintended consequences of the military being placed in a position to make decisions (related to the distribution of the vaccine) that from a normative perspective should have been made by civilian leaders, and not by military officers.] 

A second point of clarification is that it is theoretically possible to connect many political issues to the nation's "security." Problems such as racism, extremism, climate change, polarization, immigration, the lack of civil discourse in America, and others constitute problems that, broadly defined and to varying degrees, pose a potential danger to the world in which we live. But this does not mean that retired military officers should necessarily address all of these topics. For example, the nation has scientists who know far more about climate change than an average retired military officer. Thus, a normative question begins to emerge: "Should the military be actors who address this issue?"^[ Ultimately, this is an opinion question that is open for debate, but I attempt to be both charitable and reasonable: I only code issues or topics that strike me as considerably outside or tangential to relevant military expertise in the US setting.] Therefore, in looking for violations to the principle of non-interference, I try to keep in mind that even as the military has become increasingly involved in a great number of issues and events, military actors are not necessarily subject matter experts on every noteworthy topic. 

There are two further methodological points of caution worth highlighting. The first is that because some retired military officers do in fact go on to serve as appointees in political administrations, or run for office and serve as politicians themselves, it is important to control for whether a retired military officer wrote a publication while serving or having previously served in a political role that would legitimately correspond to that officer no longer having to adhere to the principles of civil-military relations in the same way that most retired military officers would. For example, we can and should hold former Senator John McCain, who retired from the Navy at the rank of Captain (O-6), to a different standard than other retired Navy Captains who do not go on to serve as US Senators. As an elected official, Senator McCain was expected to make partisan statements in his role as a Republican Senator from Arizona. Therefore, I do not include violations by retired military officers who later serve as elected or appointed partisan positions for the remainder of the statistical analysis. This specific case applies to 14 of the 391 observations (3.6% of the data), eight of which violate one or more of the principles of civil-military relations. I do not include these observations in the subsequent analysis. 

The second point of caution is that, unlike the categorical topic variable which, as explained earlier, can only take on one unique value, I allow for the possibility that a single observation can violate more than one principle of civil-military relations simultaneously. In other words, I allow for the possibility that an opinion piece can blatantly criticize the President, while making a partisan endorsement and speaking out on a topic that is at best tangentially related to the military. Such a case would constitute violating all three principles of civil-military relations at once.    

Figure \@ref(fig:norms-challenged) plots the number of challenges to each of the three central principles of civil-military relations as well as the total number of violations to these principles each year. Across the dataset, there are a total of 62 distinct violations contained in 56 pieces of commentary. this means that 321 of the 377 commentary pieces (85%) written by retired military actors not serving in high-level government appointed positions upheld the central principles of civil-military relations. 

The 56 pieces of commentary that did violate the principles of civil-military relations were written, moreover, by 31 distinct authors or author teams. This means that several authors or author teams wrote more than a single piece that violated one or more of the central principles of civil-military relations. The most prolific of violating authors in the dataset were Air Force General Michael Hayden (10 total violating pieces), Admiral William McRaven (5 violating pieces), and Lieutenant General William Odom (4 violating pieces).^[See the appendix to this chapter for a full breakdown in the data of authors and commentary pieces that I coded as having violated the central principles of civil-military relations.] 

Early on in the dataset, from 1979-1988, we can observe that there were relatively few instances of published retired military officer commentary that expressly challenged the principles of civil-military relations. From 1989 throughout the 1990s, the frequency and number of these instances slowly increased. From 2007-2012, retired officer commentary generally adhered to the central principles of civil-military relations. However, starting since roughly 2013 and through the end of the dataset in 2020, published retired military actor commentary has consistently violated at least one of the central principles of civil-military relations each year.     

```{r norms-challenged-prep, include=FALSE, warning=FALSE, message=FALSE, echo=FALSE}

# Here I create variables that measure violations
# to the central principles of CMR. 
# First I measure the # of violations to each principles
# and the # of total violations that occur. 

# Beginning with Num_Pubs_Viol, the variables are a little different.
# Num_Pubs_Viol counts the numbers of publications per year that contain
# any of the three types of violations. 

#I then make variables for the proportion of the
# annual number of publications that 
# violate each principle (Civ_Con_Prop, Non_Part_Prop, and Non_Int_Prop)
# as well as the proportion of annual pubs that violate 
# one of the central principles (Prop_Pubs_Viol)

#this data frame, violation_reg_df, is significant.  It is 
# the main data frame for measuring the violations to
# the principles of CMR and for all regressions to follow. 

violation_reg_df <- adjdataset %>% group_by(PubYr) %>% filter(Role != 1) %>% select(Author, Service, PubYr, Source, MID, Title, AuthRank, Topic, elecyear, letter_ed, Leg_Act, Crit_Insub, Issue_Area, Endorse_Partisan, Yrcount, party.mean.diff.d1.house, party.mean.diff.d1.senate, dem_diff_aff, rep_diff_aff, Inst_Cred_Gallup, HostCasRate, HostCasRateLagged) %>% mutate(
  Civ_Con_Count = sum(Crit_Insub),
  Non_Part_Count= sum(Endorse_Partisan),
  Non_Int_Count = sum(Issue_Area),
  Total_Viol_Count= (Civ_Con_Count+Non_Part_Count+Non_Int_Count),
  Num_Pubs_Viol=sum(Crit_Insub==1 | Endorse_Partisan==1 | Issue_Area==1),
  Prop_Pubs_Viol=(Num_Pubs_Viol/Yrcount),
  Civ_Con_Prop = (Civ_Con_Count/Yrcount),
  Non_Part_Prop = (Non_Part_Count/Yrcount),
  Non_Int_Prop = (Non_Int_Count/Yrcount)
  ) %>% rename(CivConViol=Crit_Insub, NonPartViol=Endorse_Partisan, NonIntViol=Issue_Area) 


# create a data frame but summarize the counts of violations by type per publishing year
violationdf_by_year_count <- violation_reg_df %>% select(PubYr, Civ_Con_Count, Non_Part_Count, Non_Int_Count, Total_Viol_Count) %>% group_by(PubYr, Civ_Con_Count, Non_Part_Count, Non_Int_Count, Total_Viol_Count) %>% summarise() %>% print()

# create the 1980 missing observation
viol_1980 <- data.frame(1980, 0, 0, 0, 0)    
#Naming the missing Data Frame - Step 2  
names(viol_1980) <- c("PubYr", "Civ_Con_Count", "Non_Part_Count", "Non_Int_Count", "Total_Viol_Count")  
#Using rbind() function to insert above observation  
violationdf_by_year_count <- rbind(violationdf_by_year_count, viol_1980)
# sum total number of all violations across the data
sum(violationdf_by_year_count$Total_Viol_Count) %>% print()

#using the pivot_longer function, turn this DF into a graphaple data frame of violation counts
violationdf_by_year_graph <- violationdf_by_year_count %>% 
  pivot_longer(Civ_Con_Count:Total_Viol_Count, names_to = "Violation_Type", values_to = "Violation_Count") %>% mutate(
    Violation_Type=case_when(
      Violation_Type=="Civ_Con_Count" ~ "Civilian Control",
      Violation_Type=="Non_Part_Count" ~ "Non-Partisanship",
      Violation_Type=="Non_Int_Count" ~ "Non-Interference",
      Violation_Type == "Total_Viol_Count" ~ "Total Violations"
                             )
  ) %>% print()

# create a data frame that has proportions of commentary violations by year
violationdf_by_year_prop <- violation_reg_df %>% select(PubYr, Civ_Con_Prop, Non_Part_Prop, Non_Int_Prop, Prop_Pubs_Viol) %>% group_by(PubYr, Civ_Con_Prop, Non_Part_Prop, Non_Int_Prop, Prop_Pubs_Viol) %>% summarise() %>% print()

# create the 1980 missing observation
viol_1980_prop <- data.frame(1980, 0, 0, 0, 0)    
#Naming the missing Data Frame - Step 2  
names(viol_1980_prop) <- c("PubYr", "Civ_Con_Prop", "Non_Part_Prop", "Non_Int_Prop", "Prop_Pubs_Viol")  
#Using rbind() function to insert above observation  
violationdf_by_year_prop <- rbind(violationdf_by_year_prop, viol_1980_prop)

#using the pivot_longer function, turn this DF into a graphaple data frame of violation counts
# note that use of filter here only keeps data for years where proportion >0, which
# means that I will not graph years if there was no
violation_prop_year_graph <- violationdf_by_year_prop %>% 
  pivot_longer(Civ_Con_Prop:Prop_Pubs_Viol, names_to = "Violation_Types", values_to = "Proportion") %>% mutate(
    Violation_Types=case_when(
      Violation_Types=="Civ_Con_Prop" ~ "Civilian Control",
      Violation_Types=="Non_Part_Prop" ~ "Non-Partisanship",
      Violation_Types=="Non_Int_Prop" ~ "Non-Interference",
      Violation_Types == "Prop_Pubs_Viol" ~ "Proportion Violating"
                             )
  ) %>% print()

```

```{r norms-challenged, include=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Instances of Retired Military Officer Commentary that Violate the Central Principles of Civil-Military Relations, 1979-2020"}

## now graph raw counts of violations by year

violationdf_by_year_graph %>% ggplot(aes(x=PubYr, y=Violation_Count)) + geom_point(aes(shape=Violation_Type, color=Violation_Type), position=position_jitter(width=.1, height=.1), alpha=.6, size=5) + scale_color_manual(values=c("tomato","dodgerblue2", "seagreen", "black"))+ labs(x="Publishing Year", y="Number of Violations By Type", shape="Violation\nType", color="Violation\nType") + theme(legend.position="bottom", axis.text.x=element_text(angle=90)) + scale_x_continuous(breaks=seq(1979, 2020, 1)) + guides(color = guide_legend(ncol=2,nrow=2,byrow=TRUE))

# trying something new
#violationdf_by_year_graph %>% ggplot(aes(x=PubYr, y=Violation_Count)) + #geom_bar(aes(color=Violation_Type)) + scale_color_manual(values=c("tomato","dodgerblue2", "seagreen", #"black"))+ labs(x="Publishing Year", y="Number of Violations By Type", shape="Violation\nType", #color="Violation\nType") + theme(legend.position="bottom", axis.text.x=element_text(angle=90)) + #scale_x_continuous(breaks=seq(1979, 2020, 1)) + guides(color = guide_legend(ncol=2,nrow=2,byrow=TRUE))
```

To account for the fact that the volume of commentary written by retired military officers has also increased over time, I express these violations of the principles of civil-military relations as a proportion of annual commentary written by retired military officers. This is shown in Figure \@ref(fig:norms-challenged-prop). When the proportion of commentary that violates the central principles is expressed, we can more clearly see that there have been problematic episodes before, most notably in the early-mid 1990s and the early 2000s. Indeed, there is a cluster of years between 1993-1998 when a noticeable proportion of retired officer commentary violated the principle of civilian control when a number of retired military officers strongly criticized former President Clinton for (in their view) failing to take proper actions in Somalia, Bosnia, Chechnya, and Iraq (related to the enforcement of no-fly zones).     

```{r norms-challenged-prop, include=TRUE, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Proportion of Annual Retired Military Officer Commentary that Violates the Central Principles of Civil-Military Relations, 1979-2020"}

violation_prop_year_graph %>% ggplot(aes(x=PubYr, y=Proportion)) + geom_point(aes(shape=Violation_Types, color=Violation_Types), position=position_jitter(width=.01, height=.001), alpha=.6, size=5) + scale_color_manual(values=c("tomato","dodgerblue2", "seagreen", "black"))+ labs(x="Publishing Year", y="Proportion of Violations By Type", shape="Violation\nTypes", color="Violation\nTypes") + theme(legend.position="bottom", axis.text.x=element_text(angle=90)) + scale_x_continuous(breaks=seq(1979, 2020, 1)) + scale_y_continuous(breaks=seq(.0, 1, .1)) + guides(color = guide_legend(ncol=2,nrow=2,byrow=TRUE))

```

A second cluster appears in the early 2000s, when several retired military officers endorsed the two Presidential Candidates running for President in 2004, the incumbent, George W. Bush, and Senator John Kerry, Bush's opponent. There were also several years (2005 and 2006) when a number of commentary pieces violated the principle of civilian control by strongly criticizing then President George W. Bush's Secretary of Defense, Donald Rumsfeld, and his leadership of the Iraq War.^[This 2006 episode is the so-called "Revolt of the Generals."]

The final cluster begins in 2013, though the proportion of commentary violating the central principles from 2013-2015 was still relatively low. Within this span of years, the year 2018 saw the highest proportion of retired officer commentary violate one or more of the central principles of civil-military relations (50%). It is also noteworthy that violations to the principle of non-interference are a somewhat recent occurrence; the first instance of a violation to this principle of civil-military relations came in 2013. 

Figure \@ref(fig:prop-violate-norms) depicts the proportion of annual commentary published by retired military officers that violates at least one of the central principles of civil-military relations. This graph largely reflects the trends enunciated by the previous figures: retired military officers strongly adhered to the principles of civil-military relations throughout the 1980s before deviating from these standards throughout the 1990s. After violating the central principles of civil-military relations in the early 2000s, retired military officer commentary returned to adhering to the standards of civil-military relations, until 2012. Since 2013, however, there has been a sharp increase in the proportion of retired military officer commentary that violates the either the principle of civilian control, non-partisanship, or non-interference of the military.  

```{r prop-violate-norms, include = TRUE, echo=FALSE, warning = FALSE, error=FALSE, message=FALSE, fig.cap="Proportion of Op-Eds Authored by Retired Military Officers That Violate Any Principles of Civil-Military Relations, 1979-2020"}

ggplot(data=violationdf_by_year_prop, mapping=aes(x=PubYr, y=Prop_Pubs_Viol)) + geom_point() + geom_smooth(color="black") + labs(x="Year", y="Proportion", color=NULL) + geom_vline(xintercept = 1981, size=.2, colour="black") + 
  geom_vline(xintercept=1989, size=.2, colour="black") + 
  geom_vline(xintercept=1993, size=.2, colour="black") + geom_vline(xintercept=2001, size=.2, colour="black") + 
  geom_vline(xintercept=2009, size=.2, colour="black") +
  geom_vline(xintercept=2017, size=.2, colour="black") +
  geom_text(aes(x=1981, label="Reagan",y=.2), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1989, label="Bush 41",y=.2), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=1993, label="Clinton",y=.4), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2001, label="Bush 43",y=.3), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2009, label="Obama",y=.4), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=2017, label="Trump 45",y=.05), colour="black", angle=90, vjust=1, text=element_text(size=9))  
```

Collectively, Figure \@ref(fig:topics-time), Figure \@ref(fig:norms-challenged), Figure \@ref(fig:norms-challenged-prop), and Figure \@ref(fig:prop-violate-norms) demonstrate that through the opinion commentary that they publish, retired military officers are addressing domestic political topics relative to other types of topics and challenging the central principles of civil-military relations at a greater rate than they did in previous decades. Having established that these trends exist, the next task is to determine what variables, if any, are driving this variation. According to the theory posited, the variables of political polarization and military prestige -- both of which rise during the period examined -- should strongly be considered. 

### Explaining A More Assertive Retired Military Officer Corps 

```{r, include = FALSE, warning=FALSE, echo=FALSE}

# Create a dataframe, quest_prof, that shows all commentary 
# that violates at least one of the central principles of CMR. 

quest_prof <- violation_reg_df %>% arrange(PubYr) %>% filter(CivConViol==1 | NonPartViol== 1 | NonIntViol==1) %>% select(Author, Title, Source, PubYr, Topic, CivConViol, NonPartViol, NonIntViol)

# count how many offending observations and how many violations by type
summary(quest_prof)    # 56 pieces violated central principles
num_distinct_offending_authors <- n_distinct(quest_prof$Author) %>% print()  # by 31 authors or author-teams
# list of offending authors
offending_authur_count <- quest_prof %>% count(Author) 
# create a table of these offending authors showing number of violations each has
table(quest_prof$Author) %>% print()


# The following dataframe does the same, but includes
# all authors, even those who may have been in a role that 
# justified violation of the principles of CMR. Thus
# I reach back to the df of 'adjdataset' here. 

adjdataset %>% arrange(PubYr) %>% 
  filter(Issue_Area ==1 | Crit_Insub== 1 | Endorse_Partisan ==1)  %>% 
  rename(Crit=Crit_Insub, Endorse=Endorse_Partisan, Interference=Issue_Area
  ) %>% 
  select (Author, Title, Source, PubYr, Topic, Crit, Endorse, Interference, Role) 

```

```{r regression prep, include = FALSE, warning = FALSE, echo=FALSE}

# Prepare data frames for regression. 

# I also scale the data for congressional polarization by multiplying by 100
# This will come in handy for the glm regressions that will occur later. 

reg_df <- violation_reg_df %>% mutate(
  any_CMR_viol=case_when(
    (CivConViol==1 | NonPartViol== 1 | NonIntViol==1) ~ 1, 
    (CivConViol !=1 & NonPartViol != 1 & NonIntViol !=1) ~ 0
  ),
  house_polar=party.mean.diff.d1.house*100,
  senate_polar=party.mean.diff.d1.senate*100,
  aff_polar=dem_diff_aff + rep_diff_aff
) %>% print()


reg_df %>% filter(letter_ed!=1) %>% print()

# The second df is a macro level df
# where the rows are years and the key variables are the number of 
# violations to the principles of CMR, by type.  
# Because some of the values for congressional polarization change by Congress and 
# not each year, I do not use affective polarization at all AND I have to 
# drop some of the multiple rows here (for the years 2007, 1999, and 1997)
# Dropping these years is the final part of the coding below. 

reg_df_macro <- reg_df %>% select(PubYr, HostCasRate, HostCasRateLagged, Civ_Con_Count, Non_Part_Count, Non_Int_Count, Total_Viol_Count, Num_Pubs_Viol, Inst_Cred_Gallup, house_polar, senate_polar, elecyear, Prop_Pubs_Viol, Yrcount) %>% group_by(PubYr, HostCasRate, HostCasRateLagged, Civ_Con_Count, Non_Part_Count, Non_Int_Count, Total_Viol_Count, Num_Pubs_Viol, Inst_Cred_Gallup, house_polar, senate_polar, elecyear, Prop_Pubs_Viol, Yrcount) %>% summarise() %>% print()

reg_df_macro <- reg_df_macro[-c(18, 22, 31), ]

# create a 1980 missing observation
reg_macro_1980 <- data.frame(1980, .438862, 0, 0, 0, 0, 0, 0, 52, 59.60248, 58.94986, 1, 0, 0)    
#Naming the missing Data Frame - Step 2  
names(reg_macro_1980) <- c("PubYr", "HostCasRate", "HostCasRateLagged", "Civ_Con_Count", "Non_Part_Count", "Non_Int_Count", "Total_Viol_Count", "Num_Pubs_Viol", "Inst_Cred_Gallup", "house_polar", "senate_polar", "elecyear", "Prop_Pubs_Viol", "Yrcount")  
#Using rbind() function to insert above observation  
reg_df_macro <- rbind(reg_df_macro, reg_macro_1980) 

```

```{r initial-regression-calcs, include=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

# This section is rather long; it's where I conduct initial regressions. 
# Important: the data frames in these sections incorporate non-smoothed values for polarization. 

# Category 1: OLS Models 
# DV - total Proportion of annual publications that violate standards, house & senate polarization

mod1_prop_ann_violate_house_lagged <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + house_polar + HostCasRateLagged, data=reg_df_macro)
summary(mod1_prop_ann_violate_house_lagged)

mod1_prop_ann_violate_sen_lagged <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + senate_polar + HostCasRateLagged, data=reg_df_macro)
summary(mod1_prop_ann_violate_sen_lagged)

# Category 2: Logistic Regression Models 

# DV - the op-ed violates any of 3 central principles, all types of polarization

mod2_anyviol_house_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house_polar + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df
    )
summary(mod2_anyviol_house_lagged)

mod2_anyviol_sen_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + senate_polar + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df
    )
summary(mod2_anyviol_sen_lagged)

mod2_anyviol_aff_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff_polar + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df
    )
summary(mod2_anyviol_aff_lagged)

# Category 3 - maybe there's bias in the source or in individual authors?
## I now include source as an independent variable, but the standard
## error estimates are too large, likely because there is not 
## enough variation within sources (LA Times is the problem).
# I first drop sources from the LA Times. 

xtabs(any_CMR_viol ~ Source, reg_df)
reg_df_slim <- reg_df %>% filter(Source != "LA Times" & Source !="USA Today") %>% print()
xtabs(any_CMR_viol ~ Source, reg_df_slim)


reg_df_slim %>% filter(any_CMR_viol ==1) %>% group_by(Author) %>% count(Author) %>% arrange(n)

# Category 3
# DV - the op-ed violates any of 3 central principles; Also includes source as an IV.

mod3_anyviol_house_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house_polar + HostCasRateLagged + AuthRank + Source,
    family=binomial(link="logit"),
    data=reg_df_slim
    )
summary(mod3_anyviol_house_lagged)

mod3_anyviol_sen_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + senate_polar + HostCasRateLagged + AuthRank +  Source ,
    family=binomial(link="logit"),
    data=reg_df_slim
    )
summary(mod3_anyviol_sen_lagged)

mod3_anyviol_aff_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff_polar + HostCasRateLagged + AuthRank +  Source ,
    family=binomial(link="logit"),
    data=reg_df_slim
    )
summary(mod3_anyviol_aff_lagged)

# Then conduct models with robust standard errors at the author level
mod3_anyviol_house_robust_lagged <- robustify(mod3_anyviol_house_lagged, cluster=Author)
summary(mod3_anyviol_house_robust_lagged)

mod3_anyviol_sen_robust_lagged <- robustify(mod3_anyviol_sen_lagged, cluster=Author)
summary(mod3_anyviol_sen_robust_lagged)

mod3_anyviol_aff_robust_lagged <- robustify(mod3_anyviol_aff_lagged, cluster=Author)
summary(mod3_anyviol_aff_lagged)

# Then conduct mixed models where we include author random effects

mod3_anyviol_house_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house_polar + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim)
summary(mod3_anyviol_house_mixed_lagged)

mod3_anyviol_sen_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + senate_polar + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim)
summary(mod3_anyviol_sen_mixed_lagged)

mod3_anyviol_aff_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff_polar + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim)
summary(mod3_anyviol_aff_mixed_lagged)

## potentially change / alter the optimizer
##check and see if the same result on the mixed model above holds for

# can include source with this data
regdata_thru2014_slim <- reg_df_slim %>% filter(PubYr <= 2014) %>% view()

mod4_anyviol_house_slim <- glm(any_CMR_viol ~ Inst_Cred_Gallup + house_polar + AuthRank + elecyear + Source + MID,
    family=binomial(link="logit"),
    data=regdata_thru2014_slim
    )
summary(mod4_anyviol_house_slim)

```

This section of the chapter incorporates advanced statistical methods investigate what role, if any, the independent variables of political polarization and military prestige play in shaping the degree to which retired military officer commentary adheres to the central principles of civil-military relations. To do this, I regress a number of different outcomes, including the proportion of annual retired officer commentary that violates at least one of the central principles of civil-military relations and the log of the odds that an op-ed authored by a retired military officer violates at least one of these central principles. 

These regression models incorporate a number of important control variables that deserve explanation. Most importantly to note for the reader, I include multiple measurements of polarization that are smoothed to determine an annual measure for each polarization type. This is helpful because measurements of polarization are regularly calculated, but not every year. The DW-NOMINATE scores from the House and Senate are assigned with each Congress every two years [@jeffrey_b_lewis_voteview_2020]. Another way political scientists often measure polarization is by examining "affective" polarization, which generally captures the differences in how partisans "feel" about their co-partisans compared to others who identify with the other major political party [@iyengar_affect_2012; @iyengar_strengthening_2018; and @iyengar_origins_2019]. However, this affective polarization likewise is not measured annually, but rather by examining data that stems from the American National Election Study (every two or every four years, by election type). However, because the base date unit that I examine in the data is the year in which an observation was published, incorporating  and using these "smoothed" measurements of the respective types of polarization makes sense.^[In the appendix, I conduct a regression analysis (See Table \@ref(tab:ch3appx1)) using non-smoothed estimates of polarization. There are two main differences in results obtained using this "stricter" codification of polarization (non-smoothed estimates of polarization) versus the "smoothed" estimates for polarization that are presented in the remainder of this paper. First, a strict, non-smoothed coding of polarization results in the coefficient for affective polarization not obtaining statistical significance. This is likely driven by the relatively low value of affective polarization obtained at the time of the 2016 election. A second and equally interesting result is that when polarization is coded strictly (non-smoothed), the coefficient for election year is also positive and statistically significant in several (logistic regression) models, whereas the analysis undertaken in the rest of this paper does not reflect the importance of an election year. The reason for this difference is likely the fact that when polarization is coded strictly, election years occur right before a new -- and almost always, higher -- measure of polarization is obtained. These results, however, are actually in total alignment: we would expect the presence of an election year to be statistically significant when polarization is strictly coded (non-smoothed) because the level of polarization in this data set almost always rises immediately after an election year (when a new Congress begins). Similarly, when we use smoothed estimates for polarization, we would expect, as the results show, that the election year itself takes on less importance because we are assuming polarization changes within intervals.] I include, therefore, smoothed measures of polarization in the US House, the US Senate, and affective polarization.^[The data on polarization in both Congressional bodies is not only readily available, but more substantively, previous scholarship has suggested that there might be a difference between the effect of polarization in each body. For instance, the US House of Representatives is a larger body of elected officials where each state is assigned proportional representation, and is sometimes viewed as less congenial than the "upper house" of the Senate. See @andrews_how_2021 and @noel_senate_2018 for more on this particular point.] 

```{r smoothed-polar, include=F, echo=F, warning=F, message=F}

# read in data sets for aff polar and cong polar
polar_aff <- read_csv("../shareddata/Aff_Polarization.csv") %>% select(Year, AffPol) %>% rename(year=Year) %>% na.omit ()

polar_cong <- read_csv("../shareddata/cong_polarization_smoothing.csv") %>% select(-congress) %>% mutate(
  house.polar=house.polar*100, 
  sen.polar=sen.polar*100
)

polar_all <- bind_rows(polar_aff, polar_cong)

polar_all <- polar_all %>% pivot_longer(AffPol:sen.polar, names_to = "value", values_to = "Score") %>% na.omit()

smoothed_polar_cong_plot <- polar_all %>% ggplot(aes(x=year, y=Score, color=value)) + geom_point(size=.7) + geom_smooth(se=FALSE) + labs(x="Year", y="Polarization Level") + scale_color_discrete(name="Polarization",
                         breaks=c("AffPol",  "house.polar", "sen.polar"),
                         labels=c("Affective\nPolarization","House\nPolarization", "Senate\nPolarization")) + scale_y_continuous() + theme(legend.position="bottom") + scale_x_continuous(breaks=seq(1980, 2020, 4))

# smoothed_polar_cong_plot --- hide this figure.  No need to show the graph, though I do need the data, above!

```

I also control for the level of military prestige by including a measure of public trust in the military. This measure comes from Gallup public opinion data that captures the level of trust that the public places in various institutions in America, such as the Presidency, Congress, Church, and the Police [@noauthor_confidence_2020]. I also include a binary indicator for whether the opinion piece was published during a calendar year in which there was a presidential election. The theoretical basis for including this control variable is that in an election year, the commentary published by retired military officers might be more likely to address the candidates or issues at stake in an upcoming election, and thus, commentary published in a presidential election year might be primed to violate the principles of civil-military relations in a way that commentary published in other years is not. 

Another control variable I include is a lagged level of casualties sustained by the US military in a given calendar year.^[This variable is constructed from a number of sources, and consists of the number of hostile US casualties sustained in a given calendar year per 100,000 active-duty military forces. I include in this measurement those casualties that are the result of what the Department of Defense classifies as either "hostile action" or a "terrorist attack." Annual data is provided from the Department of Defense from 1980-2010. I then used data from the Department of Defense regarding the wars in Iraq and Afghanistan to construct a measurement for years outside of this time range. See @department_of_defense_dcas_2011; @department_of_defense_dcas_2021; @department_of_defense_dcas_2021-1; @department_of_defense_dcas_2021-2; @department_of_defense_dcas_2021-3; @department_of_defense_dcas_2021-4; @department_of_defense_dcas_2021-5; @department_of_defense_dmdc_2021 for more details.] The theoretical basis for including this measurement is that the presence of casualties could impact the tone and tenor of opinion commentary published by retired military officers. However, it is less clear how and in what direction the presence of casualties would impact retired officer opinion commentary. One can imagine that, on one hand, a high rate of casualties could lead to retired military actors increasingly criticizing the President or other civilian officials, or the strategy undertaken in a particular war or military operation, and thus, would result in a higher level of commentary that violates one or more of the principles of civil-military relations. On the other hand, higher casualty rates might instead induce retired military actors to become more focused on the military as it undertakes a major operation or war, and that such focus would include a deliberate effort by retired military officers to not distract the military forces engaged in such an effort by publishing commentary that strains a nation's civil-military relationship. Through this second logical avenue, the presence of higher casualties might actually result in less likelihood that published retired military actor commentary violates one or more of the central principles of civil-military relations.^[Of note, I lag the level of casualties by one year. Theoretically, it is at least possible that the level of casualties sustained in a given year will shape the commentary written by retired military officers in the future. Ideally, I would use real-time or only slightly lagged casualty data, i.e., by days, weeks, or at most, months. However, this is not possible with the available data on US casualties. Monthly data for US military casualties does not exist over the entire date range of the data set. By lagging casualty rates by one year across the entire data set, I am at least able to determine if and how the presence of prior casualties drives the tenor of retired officer opinion commentary.]  

A couple more notes will help guide the reader to better understand the statistical models employed in this regression analysis. Models 1-3 rely on OLS regression, where the dependent variable is a measure of the proportion of annual commentary published by retired military officers that violates any of the three central principles of civil-military relations. There are, therefore, 42 observations (one for each year from 1979-2020) examined in these models. Models 4-9, on the other hand, incorporate logistic regression, where the dependent variable is the log of the odds that a specific commentary piece authored by a retired military officer violates any of the three central principles of civil-military relations. In these models, the unit of analysis is the individual commentary piece. For this reason, I include several other characteristics unique to the piece of commentary, including the military rank of the author as well as the source in which a piece of commentary is published. Controlling for these variables enables the researcher, respectively, to determine if an author's rank is associated with publishing commentary that violates the central principles of civil-military relations and if one or more particular newspapers are more inclined than others to publish publish commentary that violates the principles of civil-military relations. However, due to perfect separation in the data, I drop 11 observations published in the _USA Today_ and _The Los Angeles Times_ in Models 4 - 9. I also do not include 14 observations in the data written by retired military actors but who were serving in high-level government civilian appointee positions when their opinion pieces were published, for reasons explained earlier in this chapter. The analysis proceeds on 366 remaining observations.^[Models 4-6 cluster errors at the author level, while models 7-9 are mixed models that include author random effects. Both of these model designs enable the researcher to better investigate the possibility that changes in the dependent variable are driven by particular authors or types of authors.] The results are displayed in Table \@ref(tab:ch3reg1). 

```{r smooth_reg, include=F, echo=F, warning=F, error=F, message=F}
## smoothed predictions for aff_polar
loess_polar_aff <- loess(AffPol ~ year, polar_aff)
loess_polar_aff <- predict(loess_polar_aff, data.frame(year = seq(1979, 2020, 1)), se = FALSE)

## smoothed predictions for house_polar
polar_house <- polar_cong %>% select(year, house.polar)
loess_polar_house <- loess(house.polar ~ year, polar_house)
loess_polar_house <- predict(loess_polar_house, data.frame(year=seq(1979, 2020, 1), se = FALSE))

## smoothed predictions for sen_polar
polar_sen <- polar_cong %>% select(year, sen.polar)
loess_polar_sen <- loess(sen.polar ~ year, polar_sen)
loess_polar_sen <- predict(loess_polar_sen, data.frame(year=seq(1979, 2020, 1), se = FALSE))

# combine data sets
df_polar_smooth_all <- bind_cols(loess_polar_aff, loess_polar_house, loess_polar_sen)
df_polar_smooth_all <- df_polar_smooth_all %>% rename(aff.polar.smooth=1, house.polar.smooth=2, sen.polar.smooth=3)

df_polar_smooth_all_join <- df_polar_smooth_all %>% mutate(
  PubYr=seq(1979, 2020)
)

# join data sets - need to join others tomorrow with full write up. 
reg_df_macro_smoothed <- full_join(reg_df_macro, df_polar_smooth_all_join, by= c("PubYr"))

reg_df_smoothed <- full_join(reg_df, df_polar_smooth_all_join, by= c("PubYr")) %>% filter(PubYr!=1980)

reg_df_slim_smoothed <- full_join(reg_df_slim, df_polar_smooth_all_join, by= c("PubYr")) %>% filter(PubYr!=1980)


#reg models with smoothed levels of polarization
# OLS - DV is prop ann pubs violating

smth_prop_ann_violate_house_lagged <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_house_lagged)

smth_prop_ann_violate_sen_lagged <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_sen_lagged)

smth_prop_ann_violate_aff_lagged <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_aff_lagged)

# Logistic models - DV is log odds of violations

smth_anyviol_house_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + AuthRank + Source,
    family=binomial(link="logit"),
    data=reg_df_slim_smoothed
    )
summary(smth_anyviol_house_lagged)


smth_anyviol_sen_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + AuthRank +  Source ,
    family=binomial(link="logit"),
    data=reg_df_slim_smoothed
    )
summary(smth_anyviol_sen_lagged)

smth_anyviol_aff_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + AuthRank +  Source ,
    family=binomial(link="logit"),
    data=reg_df_slim_smoothed
    )
summary(smth_anyviol_aff_lagged)

# Then conduct models with robust standard errors at the author level
smth_anyviol_house_robust_lagged <- robustify(smth_anyviol_house_lagged, cluster=Author)
summary(smth_anyviol_house_robust_lagged)

smth_anyviol_sen_robust_lagged <- robustify(smth_anyviol_sen_lagged, cluster=Author)
summary(smth_anyviol_sen_robust_lagged)

smth_anyviol_aff_robust_lagged <- robustify(smth_anyviol_aff_lagged, cluster=Author)
summary(smth_anyviol_aff_lagged)

# Then conduct mixed models where we include author random effects

smth_anyviol_house_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim_smoothed)
summary(smth_anyviol_house_mixed_lagged)

smth_anyviol_sen_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim_smoothed)
summary(smth_anyviol_sen_mixed_lagged)

smth_anyviol_aff_mixed_lagged <- glmer(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + AuthRank + Source + (1 | Author), family=binomial, data=reg_df_slim_smoothed)
summary(smth_anyviol_aff_mixed_lagged)

```

\singlespace
```{r Regression Results, include=TRUE, echo=FALSE, results="asis", warning=FALSE, message=FALSE}
stargazer(smth_prop_ann_violate_house_lagged, smth_prop_ann_violate_sen_lagged, smth_prop_ann_violate_aff_lagged, smth_anyviol_house_robust_lagged, smth_anyviol_sen_robust_lagged, smth_anyviol_aff_robust_lagged, smth_anyviol_house_mixed_lagged, smth_anyviol_sen_mixed_lagged, smth_anyviol_aff_mixed_lagged,
          type="latex",
          label="tab:ch3reg1",
          title="Regression Results Using Smoothed Values of Polarization, Chapter 3", 
          covariate.labels = c('Trust in Military', 'Election Year', 'House Polarization', 'Senate Polarization', 'Aff. Polarization', 'Casualty Rate (lagged)', 'Author Rank', 'Washington Post', 'Wall Street Journal'),
          dep.var.labels = c('Proportion Violating', 'Log Odds of Violating Any Civ-Mil Principles'),
          model.names=TRUE,
          header=FALSE,
          column.sep.width = "-15 pt",
          align=TRUE,
          font.size="small",
          no.space=TRUE,
          omit.stat=c("f", "ser"),
          float.env="sidewaystable"
          )
```

\doublespace
Several results from Table \@ref(tab:ch3reg1) are worth noting. The first is the consistently positive and statistically significant coefficient for all types of polarization employed across the models. In Models 4-6 and 8-9, the respective coefficient for polarization is statistically significant at the 1% level. Additionally, because models 7-9 are mixed models that include author random effects, the fact that all three coefficients for polarization are positive and statistically significant provides moderate evidence that polarization impacts all authors in the data set rather than a small number or a subset of specific authors. In other words, the results in the data are not driven by only the opinion commentary of a few specific authors. Rather, it is the level of polarization that seems to have an effect on all of the retired military officers who take up the pen. The consistency of the positive and statistically significant coefficients for polarization suggests that increasing levels of polarization are the strongest and clearest indicator of whether retired military officer commentary will violate at least one of the principles of civil-military relations.

A second interesting result involves the coefficient for trust in the military. Note that this coefficient for trust in the military is negative and highly statistically significant in models 7-9, but not in models 1-3 and 5-6, where there is no statistical significance and the sign of the coefficient is not consistent. The lack of consistent statistical significance for the coefficient for trust in the military ultimately suggests that the prestige of the military is not a primary factor that shapes the likelihood that published retired military officer commentary violates one or more of the principles of civil-military relations. However, it should be acknowledged that the negative direction of the coefficient for trust in the military in all but two models (2-3) is nonetheless in the opposite direction of what this theory has so far predicted (the theory predicts that as the level of military prestige rises, military actors are increasingly likely to violate the principles of civil-military relations). 

Finally, it is worth highlighting that Table \@ref(tab:ch3reg1) indicates that relatively few, if any, other variables (of those investigated) influence the likelihood that published retired military officer commentary adheres to the central principles of civil-military relations. For example, the rank of an author appears to play little meaningful role in shaping whether an opinion piece adheres to standards of civil-military relations, as the coefficient for author rank is statistically insignificant in all but two models. The same is true for the rate of hostile casualties and source published. In short, the level of polarization -- regardless of polarization type -- seems to matter a great deal in shaping the content of retired officer commentary and in particular, the degree to which such commentary adheres to normative principles. 

### The Substantive Importance of Polarization

Given these results, we should also ask ourselves _how important_ is the level of polarization in shaping the content of retired military officer commentary? Substantively, the coefficient for polarization in the US House of Representatives of .009 (model 1) indicates that a one unit increase in the mean ideological distance between political parties is associated with a .9% increase in the proportion of annual commentary that violates civil-military relations. This may not seem substantively large at first, but it is key to see that this depends on how greatly polarization varies over time. For instance, within the House of Representatives in the 112th Congress, which began in January 2011, polarization levels were nearly six points higher than the level that existed in the immediate session of Congress. This would suggest that in the span of just two years -- one session of Congress -- the proportion of annual opinion commentary authored by retired military officers that violates civil-military relations principles increased by 5.4%. Viewed through this lens, the substantive importance of polarization is greater than what the coefficient may indicate to us at first.   

The coefficients of .122, .084, and .058 for each respective polarization type in models 4-6 correspond to a 12.9, 8.7, and 6.0 percent increase in the the odds that a commentary publication authored by a retired military officer challenges or violates one of the central principles of civil-military relations for every one unit increase in the level of House, Senate, and affective polarization. In short, the results show that as polarization rises, the casual reader of the op-ed section of a major newspaper is increasingly more likely to come across commentary authored by retired military officers that either sharply criticizes civilian leaders, adopts a partisan position, or addresses a topic that is indirectly related to defense issues. 

```{r ch3-by-principle, include=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

# Category 2: Now run Logistic and Mixed Model Regression where the DV now becomes the log of the odds that an individual op-ed actually violates one or more of the principles of CMR.   
# use smoothed variable estimates in chapter, and strict measures in appendix

# DV - violation of civilian control

smth_civcontrol_house_lagged <- glm(CivConViol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_civcontrol_house_lagged)

smth_civcontrol_sen_lagged <- glm(CivConViol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_civcontrol_sen_lagged)

smth_civcontrol_aff_lagged <- glm(CivConViol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_civcontrol_aff_lagged)

# DV - violation of non-partisan ethic
smth_nonpart_house_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_house_lagged)

smth_nonpart_sen_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_sen_lagged)

smth_nonpart_aff_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_aff_lagged)

# DV - violation of a norm of non_interference

smth_nonint_house_lagged <- glm(NonIntViol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonint_house_lagged)

smth_nonint_sen_lagged <- glm(NonIntViol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonint_sen_lagged)

smth_nonint_aff_lagged <- glm(NonIntViol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonint_aff_lagged)

```

### Testing Violations of Each Central Principle Separately

We can conduct further statistical analysis to determine the likelihood that an opinion piece published by a retired military actor violates _each_ principle of civil-military relations separately. This may establish a relationship between the level of polarization and the violation of a specific principle of civil-military relations, which could prove insightful towards informing the broader theory laid out in the book thus far. The results are displayed in Table \@ref(tab:ch3reg2). In models 1-3, the dependent variable is the log of the odds that an opinion piece authored by a retired military officer violates the principle of civilian control; in models 4-6, the dependent variable is the log of the odds that an opinion publication violates the principle of non-partisanship; and in models 7-9, the dependent variable is the log of the odds that a publication authored by a retired military officer violates the principle of non-interference. 

\singlespace
```{r ch3-Regression Individual Principles, include=TRUE, echo=FALSE, results="asis", warning=FALSE, message=FALSE}
stargazer(smth_civcontrol_house_lagged, smth_civcontrol_sen_lagged, smth_civcontrol_aff_lagged, smth_nonpart_house_lagged, smth_nonpart_sen_lagged, smth_nonpart_aff_lagged, smth_nonint_house_lagged, smth_nonint_sen_lagged, smth_nonint_aff_lagged,
          type="latex",
          label="tab:ch3reg2",
          title="Regression Results: Log Odds of Breaking Individual Central Principles of Civil-Military Relations", 
          covariate.labels = c('Trust in Military', 'Election Year', 'House Polarization', 'Senate Polarization', 'Aff. Polarization', 'Hostile Casualty Rate (lagged)', 'Rank'),
          dep.var.labels = c("Violates Civilian Control", 'Violates Non-Partisanship', 'Violates Non-Interference'),
          model.names=TRUE,
          header=FALSE,
          column.sep.width = "-15pt",
          align=TRUE,
          font.size="small",
          no.space=TRUE,
          omit.stat=c("f", "ser"), 
          float.env="sidewaystable"
          )
```
\doublespace

Again, there are some important results worth highlighting in Table \@ref(tab:ch3reg2). First, note that the coefficient for each type of polarization is positive and highly statistically significant in models 1-3, where the dependent variable corresponds to a violation of the principle of civilian control. This suggests that changes to any level of polarization are strongly associated with an increased likelihood that a retired military officer commentary piece particularly violates the principle of civilian control, which in this chapter was operationalized to sharp criticism of the President or Secretary of Defense. Second, note that in models 4-6, when the dependent variable corresponds to a violation of the principle of non-partisanship, it is the coefficient for election year that is positive and highly statistically significant, whereas the coefficients for each type of polarization actually switch signs and, in two of the three cases, do not hold statistical significance.  

What does this mean, and how should we interpret this? Importantly, this means that retired officer commentary authored in an election year is the strongest and clearest predictor of whether published commentary by military actors violates the specific principle of non-partisanship, rather than the polarization level in the country. This result is generally reasonable, and not one at odds with the overall theory presented in this book. However, we can further investigate how an election year and polarization impact the likelihood that a retired military officer opinion publication violates the principle of non-partisanship specifically. I run models 4-6 again, but drop the control for election year, on the basis that perhaps the control for election year is capturing some of the work that polarization might be doing. The results are displayed in Table \@ref(tab:ch3reg3).

```{r ch3 non-part test, include=FALSE, echo=FALSE, message=FALSE}
## Further Checks on the Violation of the Principle of Non-Partisanship
## Drop control for election year. 

# DV - violation of non-partisan ethic
smth_nonpart_house_appx_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + house.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_house_appx_lagged)

smth_nonpart_sen_appx_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + sen.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_sen_appx_lagged)

smth_nonpart_aff_appx_lagged <- glm(NonPartViol ~ Inst_Cred_Gallup + aff.polar.smooth + HostCasRateLagged + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_nonpart_aff_appx_lagged)

```

\singlespace
```{r ch3-more robustness tests, include=TRUE, echo=FALSE, results="asis", warning=FALSE, message=FALSE}
stargazer(smth_nonpart_house_appx_lagged, smth_nonpart_sen_appx_lagged, smth_nonpart_aff_appx_lagged,
          type="latex",
          label="tab:ch3reg3",
          title="Regression Results: Log Odds of Retired Military Officer Commentary Violating the Principle of Non-Partisanship without Controlling for Election Year", 
          covariate.labels = c('Trust in Military', 'House Polarization', 'Senate Polarization', 'Aff. Polarization', 'Hostile Casualty Rate', 'Rank'),
          dep.var.labels = c('Violation of the Principle of Non-Partisanship'),
          model.names=TRUE,
          header=FALSE,
          column.sep.width = "1pt",
          align=TRUE,
          font.size="small",
          no.space=TRUE,
          omit.stat=c("f", "ser")
          )

```
\doublespace

Table \@ref(tab:ch3reg3) shows that when the controls for election year are removed, the coefficients for polarization remain statistically insignificant, but that the coefficient for author rank is positive and statistically significant. These results suggest that we cannot conclusively state that increasing polarization directly leads to an increase in the likelihood that retired military officer commentary violates the principle of non-partisanship specifically. The positive and statistically significant coefficient for rank of the author matters when the dependent variable is the violation of the principle of non-partisanship. If we conceive of violations of the principle of non-partisanship as op-eds that endorse or attack political candidates running for office during an election year, the positive and statistically significant coefficient for the rank of an author is not intuitively surprising. Indeed, we might very well expect that military retirees who held higher ranks during their time in service are those that will engage in this type of specific behavior, presumably because the public is more inclined to listen to them. 

Integrating the main regression results with the results of regressing each principle separately leads us to conclude that rising polarization leads to an increase in the likelihood that retired military officer commentary violates _at least one_ of the principles of civil-military relations, and the principle of civilian control in particular. The data do not allow us to state, however, that increasing polarization leads to an increase in the likelihood that retired officer commentary will violate each and every central principle of civil-military relations. 

### The Interaction of Polarization and Prestige

We can also seek to determine if the data reflect any meaningful relationship between the interaction of polarization and military prestige. This stems from the broader theoretical point made in Chapter 2 that when both polarization and military prestige are high, we are more likely to witness civil-military tension. I therefore include interaction terms for each type of polarization and military prestige. The dependent variable is the proportion of annual commentary (models 1-3) and the log of the odds (models 4-6) that a particular opinion piece violates at least one central principle of civil-military relations. These results are displayed in Table \@ref(tab:ch3-intreg).

```{r ch3-interaction-terms, include=FALSE, warning=FALSE, echo=FALSE, message=FALSE}

# dv - proportion of pubs violating

smth_prop_ann_violate_house_lagged_int <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup*house.polar.smooth, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_house_lagged_int)

smth_prop_ann_violate_sen_lagged_int <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup*sen.polar.smooth, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_sen_lagged_int)

smth_prop_ann_violate_aff_lagged_int <- lm(Prop_Pubs_Viol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup*aff.polar.smooth, data=reg_df_macro_smoothed)
summary(smth_prop_ann_violate_aff_lagged_int)


# dv - log of the odds a piece violates any principles
smth_anyviol_house_lagged_int <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup*house.polar.smooth + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_anyviol_house_lagged_int)

smth_anyviol_sen_lagged_int <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + sen.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup * sen.polar.smooth  + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_anyviol_sen_lagged_int)

smth_anyviol_aff_lagged_int <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + aff.polar.smooth + HostCasRateLagged + Inst_Cred_Gallup * aff.polar.smooth  + AuthRank,
    family=binomial(link="logit"),
    data=reg_df_smoothed
    )
summary(smth_anyviol_aff_lagged_int)


# Marginal Effects Prep and Check
mod3_anyviol_house_int_lagged <- glm(any_CMR_viol ~ Inst_Cred_Gallup + elecyear + house_polar + HostCasRateLagged + AuthRank + Source + Inst_Cred_Gallup*house_polar,
    family=binomial(link="logit"),
    data=reg_df_slim
    )
summary(mod3_anyviol_house_int_lagged)
  
margins(mod3_anyviol_house_int_lagged, at = list(house_polar = seq(30,110, by=5)))
summary(margins(mod3_anyviol_house_int_lagged, variables = "Inst_Cred_Gallup", at = list(house_polar = seq(30,110, by=5))))

margins(mod3_anyviol_house_int_lagged, at = list(Inst_Cred_Gallup = seq(20,95, by=5)))
summary(margins(mod3_anyviol_house_int_lagged, variables = "house_polar", at = list(Inst_Cred_Gallup = seq(20,95, by=5))))

```

\singlespace
```{r int-terms-ch3, include=TRUE, echo=FALSE, results="asis", warning=FALSE, message=FALSE}
stargazer(smth_prop_ann_violate_house_lagged_int, smth_prop_ann_violate_sen_lagged_int, smth_prop_ann_violate_aff_lagged_int, smth_anyviol_house_lagged_int, smth_anyviol_sen_lagged_int, smth_anyviol_aff_lagged_int, 
          type="latex",
          label="tab:ch3-intreg",
          title="Interacting the Levels of Prestige and Polarization", 
          covariate.labels = c('Trust in Military', 'Election Year', 'House Polarization',  'Senate Polarization', 'Aff. Polarization', 'Hostile Casualty Rate (lagged)', 'Author Rank', 'Prestige*Polarization (House)', 'Prestige*Polarization(Senate)', 'Prestige*Polarization(Aff.)'),
          dep.var.labels = c('Proportion Violating', 'Log Odds Any Violation'),
          model.names=TRUE,
          header=FALSE,
          column.sep.width = "-15 pt",
          align=TRUE,
          font.size="small",
          no.space=TRUE,
          omit.stat=c("f", "ser")
          )
```

\doublespace

Table \@ref(tab:ch3-intreg) shows that the interaction between the levels of polarization and the prestige of the military do not appear to matter significantly. To see this, note that in every instance in which an interaction term appears to be statistically significant (models 2, 5, and 6), the corresponding coefficient in the same model for polarization is also positive and statistically significant. Overall, these results strongly suggest that it is not the interaction of prestige and polarization that seems to matter, but rather the raw level of polarization that strongly shapes the degree to which retired military officer commentary adheres to normative standards.  

### Predicted Probability

We now shift gears to better understand and interpret the substantive impact of rising polarization on the likelihood that retired military officer commentary violates one or more of the central principles of civil-military relations. To do this, we can use the results of our previous regression analysis to vary variables of interest while holding other variables constant. Using logistic regression models 4 and 6 from Table \@ref(tab:ch3reg1), I fix the year in which a piece is published as an election year, the source in which a piece is published as _The Wall Street Journal_, and hold all other values, such as author rank and level of military prestige, at their respective means, while varying the level of polarization in the US House of Representatives. This result is displayed in Figure \@ref(fig:pred-prob-house). 

```{r predicted probabilities-house, include=FALSE, warning=FALSE, message=FALSE, error=FALSE}

# Hold values of Author Rank and Institutional Credibility at their mean
# Vary the Level of Senate Polarization from its minimum value to an arbitrary 
# level of 120, which is higher than it currently is but not theoretically impossible.  

predictiondata <- tibble(house.polar.smooth=seq(min(reg_df_smoothed$house.polar.smooth), 100, by=1), Inst_Cred_Gallup = mean(reg_df_smoothed$Inst_Cred_Gallup), AuthRank=mean(reg_df_smoothed$AuthRank), elecyear=max(reg_df_smoothed$elecyear), HostCasRateLagged=mean(reg_df_smoothed$HostCasRateLagged), Source="WSJ") %>% crossing(any_CMR_viol = c(0,1)) 


augment(smth_anyviol_house_lagged, newdata = predictiondata, se_fit=TRUE)

# prediction data
predictions <- augment(smth_anyviol_house_lagged, newdata=predictiondata, se_fit=TRUE) %>% 
  mutate(
    .prob=plogis(.fitted),
    conf.low = plogis(.fitted - (qnorm(.975) * .se.fit)),
    conf.high = plogis(.fitted + (qnorm(.975) * .se.fit)),
    pred_final_rec = case_when(
      .prob >= .5 ~ "Likely",
      .prob < .5 ~ " Not likely"
    )
  )

predictions %>% arrange(.prob, .fitted, any_CMR_viol, desc(.fitted))

# now let's try some graphs
# notice that the predictions are not in (0, 1)
ggplot(predictions) +
  aes(x = .fitted) +
  geom_histogram()

# if we wanted predictions on the probability scale,
#   we predict on the log scale,
#   then apply inverse-logit (logistic CDF)
# use plogis(): cumulative probability of the logistic distribution

# demonstration: scatter log odds (x) and predicted probability (y)
# with 95% CIs
# (CIs don't look smooth in this example because .se.fit depends on X data)
predictions %>%
  ggplot() +
  aes(x = .fitted, y = .prob) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_smooth() 

```

```{r predicted probabilities-aff, include=FALSE, warning=FALSE, message=FALSE, error=FALSE}

# Hold values of Author Rank and Institutional Credibility at their mean
# Vary the Level of House Polarization from its minimum value to an arbitrary 
# level of 120, which is higher than it currently is but not theoretically impossible.  

predictiondataaff <- tibble(aff.polar.smooth=seq(min(reg_df_smoothed$aff.polar.smooth), 100, by=1), Inst_Cred_Gallup = mean(reg_df_smoothed$Inst_Cred_Gallup), AuthRank=mean(reg_df_smoothed$AuthRank), elecyear=max(reg_df_smoothed$elecyear), HostCasRateLagged=mean(reg_df_smoothed$HostCasRateLagged), Source="WSJ") %>% crossing(any_CMR_viol = c(0,1)) 

augment(smth_anyviol_aff_lagged, newdata = predictiondataaff, se_fit=TRUE)

# prediction data
predictionsaff <- augment(smth_anyviol_aff_lagged, newdata=predictiondataaff, se_fit=TRUE) %>% 
  mutate(
    .prob=plogis(.fitted),
    conf.low = plogis(.fitted - (qnorm(.975) * .se.fit)),
    conf.high = plogis(.fitted + (qnorm(.975) * .se.fit)),
    pred_final_rec = case_when(
      .prob >= .5 ~ "Likely",
      .prob < .5 ~ " Not likely"
    )
  )

predictionsaff %>% arrange(.prob, .fitted, any_CMR_viol, desc(.fitted))

# now let's try some graphs
# notice that the predictions are not in (0, 1)
ggplot(predictionsaff) +
  aes(x = .fitted) +
  geom_histogram()

# if we wanted predictions on the probability scale,
#   we predict on the log scale,
#   then apply inverse-logit (logistic CDF)
# use plogis(): cumulative probability of the logistic distribution

# demonstration: scatter log odds (x) and predicted probability (y)
# with 95% CIs
# (CIs don't look smooth in this example because .se.fit depends on X data)
predictionsaff %>%
  ggplot() +
  aes(x = .fitted, y = .prob) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_smooth() 

```

```{r pred-prob-house, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Predicted Probability of House Polarization\n Levels on Retired Military Officer Opinion Publications Violating Principles of Civil-Military Relations", fig.height=4.5, fig.width=6}
predictions%>%
  ggplot() +
  aes(x = house.polar.smooth, y = .prob) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_smooth(color="black") + labs(
    x="Level of Polarization in the House (Scaled)",
    y="Predicted Probability"
  ) + scale_y_continuous(breaks=seq(-.1, 1.1, .1)) + 
 geom_vline(xintercept = 59.66, size=.2, colour="black") + 
  geom_vline(xintercept=71.33, size=.2, colour="black") +
  geom_vline(xintercept=78.8, size=.2, colour="black") + 
  geom_vline(xintercept=84.27, size=.2, colour="black") +
  geom_vline(xintercept=88.6, size=.2, colour="black") +
  geom_text(aes(x=59.66, label="1979",y=.5), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=71.33, label="1993",y=.5), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=78.8, label="2001",y=.5), colour="black", angle=90, vjust=-.3, text=element_text(size=9)) + 
  geom_text(aes(x=84.27, label="2011",y=.65), colour="black", angle=90, vjust=-.3, text=element_text(size=9))  + 
  geom_text(aes(x=88.6, label="2021", y=.65), colour="black", angle=90, vjust=1.1, text=element_text(size=9))
```

The vertical colored lines cross the x-axis at the scaled level of smoothed polarization in a particular year, and the color of the line indicates the party of the President at the time Congress was seated in a particular year, or, in the case of an inaugural year, the party of the president-elect.
 
```{r pred-prob-aff, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Predicted Probability of Affective Polarization\n Levels on Retired Military Officer Opinion Publications Violating Principles of Civil-Military Relations", fig.height=4.5, fig.width=6}
predictionsaff%>%
  ggplot() +
  aes(x = aff.polar.smooth, y = .prob) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_smooth(color="black") + labs(
    x="Level of Affective Polarization in the US (Scaled)",
    y="Predicted Probability"
  ) + scale_y_continuous(breaks=seq(-.1, 1.1, .1)) + 
  geom_vline(xintercept = 49.01, size=.2, colour="black") + 
  geom_vline(xintercept=55.1, size=.2, colour="black") +
  geom_vline(xintercept=63.77, size=.2, colour="black") + 
  geom_vline(xintercept=80.45, size=.2, colour="black") +
  geom_vline(xintercept=72.72, size=.2, colour="black") +
  geom_vline(xintercept=92.93, size=.2, colour="black") +
  geom_text(aes(x=49.01, label="1979",y=.5), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=55.1, label="1993",y=.5), colour="black", angle=90, vjust=1, text=element_text(size=9)) + 
  geom_text(aes(x=63.77, label="2001",y=.5), colour="black", angle=90, vjust=-.3, text=element_text(size=9)) + 
  geom_text(aes(x=80.45, label="2009",y=.65), colour="black", angle=90, vjust=1.1, text=element_text(size=9)) + 
  geom_text(aes(x=72.72, label="2011",y=.65), colour="black", angle=90, vjust=-.3, text=element_text(size=9))  + 
  geom_text(aes(x=92.93, label="2021", y=.68), colour="black", angle=90, vjust=1.1, text=element_text(size=9))
```

If we use levels of affective polarization instead, we see a similar picture emerge, as shown in Figure \@ref(fig:pred-prob-aff). The overall trajectories of the curve are similar in both figures, but there are a couple of distinct points of comparison to make.^[The shape of the graph using the level of polarization in the Senate is very nearly the same as when using polarization in the House; therefore, I only include one graph.] 

First, the confidence intervals in each graph tell a slightly different but in some ways similar story. Note that in both graphs, the upper bound of the confidence interval that corresponds to the level of House and affective polarization in 1979 is less than the lower bound of the confidence interval for either level of polarization in 2021. In other words, in 1979, the probability that a publication authored by a retired military officer violated one of the principles of civil-military relations was _at most_ 8% (using the level of polarization in the House, as shown in Figure \@ref(fig:pred-prob-house)) or 13% (using the level of affective polarization, as shown in Figure \@ref(fig:pred-prob-aff)). In 2021, the probability that an opinion publication authored by a retired military officer violates one of the central principles of civil-military relations was _at least_ 17% (using the level of polarization in the House, as shown in \@ref(fig:pred-prob-house)) or 20% (using the level of affective polarization, as shown in Figure \@ref(fig:pred-prob-aff)). This means that what would have been statistically improbable is more or less guaranteed today: roughly one out of every five pieces of opinion commentary authored by a retired military officer will violate one or more of the central principles of civil-military relations. 

The broader point is that the United States is no longer characterized by the relatively tame polarization levels that existed even just a few decades ago. American society has become increasingly marked by intense polarization, reflecting a deep division among citizens over the worldviews, moral values, and common sense of purpose that should guide the state. When we examine the predicted probabilities as shown in Figure \@ref(fig:pred-prob-house) and Figure \@ref(fig:pred-prob-aff), it becomes clear that, assuming polarization continues to rise, the degree to which retired military officers will adhere to the principles of civil-military relations in the future is highly volatile. The range of the confidence intervals grows as polarization takes on higher values. 

If we take these larger confidence intervals at face value, they thus predict that in any given year of relatively high polarization, retired military officers may very well publish a lot of commentary that violates the principles of civil-military relations, or they may publish relatively very few that do. This statistical volatility underscores the point that as polarization deepens, retired military officers may end up adhering to the central principles of civil-military relations -- or they may not -- in any particular year or period of time. The broader question this raises is whether such volatility is acceptable, either to the American public, or to any number of other civilian and military actors. Does the nation wish its cadre of retired military officers to speak publicly, and to adhere to the broad principles of civilian control, non-partisanship, and non-interference when they do? To the degree that one wishes the answers to these questions to be yes, the statistical models shown in this paper predict a somewhat grim future if polarization continues to rise.   

### Interpreting the Data and its Impact on the Theory

This section summarizes and interprets the fairly in-depth statistical analysis undertaken in the preceding pages of this chapter. The main takeaway is that the data seem to provide moderate support for H1, which stated that military actors increasingly violate the central principles of civil-military relations when polarization is high relative to periods of low polarization. The strongest evidence in support this claim was presented in the regression results shown in Table \@ref(tab:ch3reg1). Here the coefficients for all types of polarization were consistently positive and statistically significant, indicating that as polarization rises, we can expect that opinion commentary authored by retired military officers will increasingly violate at least one of the principles of civil-military relations.  
These statistical analysis was not uniformly robust, however, in regression models where the dependent variable was a violation of each of the three individual principles of civil-military relations. The data did suggest that rising polarization levels increase the likelihood that a piece of opinion commentary authored by a retired military officer will violate the principle of civilian control, but not the principles of non-partisanship or non-interference, respectively. In sum, the results suggest that as polarization rises, there is increasing likelihood that retired military officer commentary will violate at least one principle of civil-military relations, and the principle of civilian control in particular. Practically, we can expect this to mean that as polarization rises, retired military officers will publish commentary that increasingly criticizes the President and/or the Secretary of Defense in blatant and obvious ways. 

This chapter found no support for H2, however, which stated that military actors increasingly violate the central principles of civil-military relations when military prestige is high relative to periods of low military prestige. In fact, across multiple model specifications, the coefficient for military prestige lacked consistency, both in terms of direction and statistical significance. The only exception to this was the fact that high ranking officers in particular were found to be more likely to violate the principle of non-partisanship when controls for election year are removed, as shown in Table \@ref(tab:ch3reg3).

These statistical observations are important to note with respect to the theory offered in the previous chapter of this book. To be clear, observational data can only provide the researcher with so many clues, and in that respect, this chapter cannot conclusively state that each military actor who published commentary that violated the central principles of civil-military relations did so because they were personally motivated to do so out of an interest in promoting a particular worldview, and to see that worldview implemented a particular way in politics. At the same time, the observational data examined in this chapter does point in a direction that is nonetheless highly consistent with the theoretical claims offered thus far in the book. 

The increase in both the number and proportion of commentary published by retired military actors that violates the principles of civil-military relations over the time period examined, the observable change between the earlier and latter periods of time in the topical distribution of opinion commentary that violated the central principles, and the consistently positive and statistically significant results of polarization that were uncovered in the much of the statistical regression analyses all consistent with the point that as polarization rises, issues that involve the _Image of God_ in our politics generate contestation and disagreement about how best to shape policies that consider these issues. The data examined in this chapter fits, moreover, with the notion that because these types of issues contain significant moral undertones, even retired military actors are increasingly likely to behave in ways that advance the worldviews they hold to and their ideas for how best to implement policies related to their worldviews, over and above the professional military ethic these same actors espoused for so many years while on active duty. At the very least, the evidence presented and analyzed in this chapter is right in line with the theoretical claim that highly polarized environments increase the frequency and the potential disparity in policy outcomes, which in turn generates a choice for military actors either to quietly say nothing, or to speak, but in so doing, to do so in a way that actually or is perceived to violate one or more principles of civil-military relations. That more military actors during an era of higher polarization are in fact speaking up, and in ways that increasingly challenge the principles of civil-military relations, further underscores the theoretical claim that rising polarization provides a _motive_ for military actors to behave in ways that challenge the central principles of civil-military relations.    

### Alternate Explanations

To further understand the limitations of our findings in this chapter, however, we need to consider what, if any, alternate explanations may exist --- that is, if polarization is _not_ responsible for the variation in the degree to which retired military officer commentary violates one or more of the central principles of civil-military relations, what else could be responsible? I address two of these here --- the conflict/threat environment, and the phenomenon of norm change among the retired military officer community.  

Perhaps military actors are more inclined to author opinion commentary that is primed to criticize civilian leaders when the military is engaged in fighting overseas, or when casualties are incurred. Perhaps the opposite is true, and retired military officers actually wish to be less of a distraction to forces engaged in fighting, and thus speak less on topics that could strain the country's civil-military relationship when troops are deployed overseas participating in the conduct of war. 

Even if we are not sure in which direction or how the threat environment might induce military actors to publish opinion commentary differently, this logic is, at least on the surface level, somewhat compelling. At the same time, though, the statistical analysis conducted in this chapter was at least partially able to inquire along this line by including a hostile casualty rate as a control variable in several regression model specifications. In all but a few places, the hostile casualty rate was statistically insignificant, and furthermore, in the few times the lagged hostile casualty rate did appear statistically significant, it was always in the negative direction. This suggests that, if anything, rising casualties are associated with fewer opinion commentary pieces authored by retired military officers and thus less likelihood of an opinion piece violating one or more of the principles of civil-military relations. Thus, at least on the basis of what has been examined in this chapter, there is little evidence supporting this first alternative line of inquiry involving the idea that rising casualties during conflict operations spur retired military officers to increasingly publish opinion commentary that violates the principles of civil-military relations.

A more difficult alternate explanation to discard is that of norm change regarding the role of retired military officers and public life altogether. Could it be that from 1979-2020, successive cohorts of retired military officers have progressively adopted a viewpoint that has gradually differed from their predecessors such that although previous cohorts of retirees may have believed in staying out of politics altogether, recent military retiree cohorts no longer see the need to do so? Ideally, we would want more survey data or more first-hand statements from retired military officers, such as that of General Omar Bradley's presented in this paper's introduction, that speaks to how these retired officers view their role in public discourse. The closest thing we do have to a statement such as Bradley's is in fact an opinion piece authored by Army General Martin Dempsey, who also served as Chairman of the Joint Chiefs of Staff, which was published in _The Washington Post_ in 2016. In this piece he criticized both the retired officers who spoke and the presidential candidates who had asked them to speak at the respective party conventions ahead of the 2016 Presidential Election. Dempsey's words clearly articulate his views on the role of retired military actors: "As generals, they have an obligation to uphold our apolitical traditions. They have just made the task of their successors - who continue to serve in uniform and are accountable for our security -- more complicated. It was a mistake for them to participate as they did. It was a mistake for our presidential candidates to ask them to do so" [@dempsey_military_2016]. 

We may not have the significant survey data or first-hand statements of retired military officers to conclusively adjudicate this option of role change as an alternate explanation, but what we do have are a couple of data points for at least an individual officer that allow us to compare and contrast what they stated while on active duty versus what they have said while retired (courtesy of the data examined in this chapter). Admiral Mike Mullen, who also served as the Chairman of the Joint Chiefs of Staff, makes for a good case in point. For instance,  Mullen penned a rare open letter to the force while serving as the Chairman of the Joint Chiefs of Staff in which he stated, "What I am suggesting - indeed, what the Nation expects - is that military personnel will, in the execution of the mission assigned to them, put aside their partisan leanings. _Political opinions have no place in cockpit or camp or conference room. We do not wear our politics on our sleeve_" [@mullen_chairman_2008, italics mine]. To be clear, Mullen was addressing active officers in these remarks, and not retired military officers directly. But it is highly unlikely that at Mullen's opinions are any different than that of Dempsey's. As a sitting Chairman of the Joint Chiefs of Staff, surely Mullen understood that there is a relationship between the active-duty officer corps, especially its senior leaders, and its retired officer corps. 

Yet we should examine what Mullen has said in the years since leaving duty and up through 2020. The data show that through 2020, Mullen had written six opinion pieces published in major newspapers since leaving active duty, three of which challenged, if not violated, the principles of civilian control and non-partisanship. The titles of these pieces alone are, in my view, instructive: "Bannon Has No Place on the NSC," "The Refugees We Need," and "Banning Transgender Troops Only Hurts Us." While I do not doubt the sincerity of Mullen's opinions, nor the fact that the political positions expressed in these op-eds may be reasonable, my concern is whether an independent observer of these titles alone could conclude, either now or at the time these publications were penned, that Mullen does not provide at least the perception of possessing an ideological leaning that favors one political party or platform over the other.^[The point I am making here is that Mullen did not just write one op-ed, nor several op-eds that had no reference to any partisan idea or entity. These are three op-eds that clearly align, intentionally or not, with either a partisan entity or its platform. Mullen also wrote a lengthy piece in _The Atlantic_ following protests in the summer of 2020 entitled, "I Cannot Remain Silent." Chapter 6 discusses the behavior of retired military officers in 2020 in more detail.] 

The question then follows as to why or how could Mullen, when on active duty, plead with the active force to stay out of politics, but then, as a retired officer, behave in such a way that indicates an incredible willingness to engage? Perhaps the norms really did change significantly in the years since Mullen retired in 2011 and the end of the data explored in this chapter, 2020. But my contention is that it is far more likely the case that the theory laid out in this book holds a more satisfactory answer. Through the lens of the theory I have offered, during the nine years in between Mullen's retirement from active duty and the end of 2020, polarization in the United States significantly increased. This coincided with a number of important issues that were thrust into our politics, issues that were comprised of heavy moral undertones related to the _Image of God._ Two of the three pieces Mullen penned that I claim violated one of the central principles of civil-military relations speak to the topics of transgender people and to refugees, both of which involve, as explained in the previous chapter, a significant _Imago Dei_ component. The formal and informal prohibitions on conduct of active-duty versus retired military actors have not changed at all. It is thus far more likely the case, then, that to the extent norms are changing concerning the political conduct of retired military officers, these norms are changing because the retired officers themselves are engaging in conduct that is itself changing the norms. The theory offered here helps provide an answer.  

## Conclusion

It remains to be seen whether and the degree to which polarization will worsen in the years to come, and whether the retired military officer community as a whole can reverse or at least slow the trends uncovered in this chapter. More concerning, we are not entirely sure if retired military officers will even want to slow these trends. If polarization continues to deepen, we should expect retired military officers to increase the level with which they violate historical central principles of civil-military relations, certainly through the op-eds they publish, but perhaps through a variety of other behaviors that are available to them to undertake.

This chapter explored one specific type of political behavior, the act of publishing opinion commentary, undertaken by a specific subset of military actors, retired military personnel. The chapter found moderate evidence in support of H1, which suggests that rising political polarization is associated with an increase in political behavior undertaken by military actors that violate one or more of the central principles of civil-military relations. The statistical evidence uncovered in this chapter, moreover, was at the very least consistent with the notion that as political polarization rises, issues that squarely relate to the _Image of God_ are increasingly thrust into our politics. This idea is also consistent with the notion that rising polarization in a society provides a _motive_ for military actors to behave in ways that violate the central principles of civil-military relations. We now turn to another empirical chapter in which we examine a different type of behavior undertaken by civilian rather than military actors that can thrust the military into politics and, on occasion, violate the central principles of civil-military relations.    


```{r ch3-save-dataframes, include=F, echo=F, warning=F, error=F, message=F}
ch3_appx_data_list = list(quest_prof=quest_prof, 
                          reg_df=reg_df, 
                          reg_df_macro=reg_df_macro, 
                          reg_df_slim=reg_df_slim, 
                          mod1_prop_ann_violate_house_lagged = mod1_prop_ann_violate_house_lagged,
                          mod1_prop_ann_violate_sen_lagged = mod1_prop_ann_violate_sen_lagged,
                          mod3_anyviol_house_robust_lagged=mod3_anyviol_house_robust_lagged,
                          mod3_anyviol_sen_robust_lagged=mod3_anyviol_sen_robust_lagged,
                          mod3_anyviol_aff_robust_lagged=mod3_anyviol_aff_robust_lagged,
                          mod3_anyviol_house_mixed_lagged=mod3_anyviol_house_mixed_lagged,
                          mod3_anyviol_sen_mixed_lagged=mod3_anyviol_sen_mixed_lagged,
                          mod3_anyviol_aff_mixed_lagged=mod3_anyviol_aff_mixed_lagged)

saveRDS(ch3_appx_data_list, "../shareddata/ch3_appx_data_list.rds")

rm(list=ls())
```
\pagebreak












